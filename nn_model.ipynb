{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the LSTM-based architecture for the Advantage Actor-Critic (A2C) agent\n",
    "class A2CNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, hidden_size_policy=48, hidden_size_value=48, num_actions=4\n",
    "    ):\n",
    "        super(A2CNetwork, self).__init__()\n",
    "\n",
    "        # LSTM for both Policy and Value functions\n",
    "        self.lstm_policy = nn.LSTM(input_size, hidden_size_policy, batch_first=True)\n",
    "        self.lstm_value = nn.LSTM(input_size, hidden_size_value, batch_first=True)\n",
    "\n",
    "        # Fully connected layers for Policy (Actor)\n",
    "        self.fc_policy = nn.Linear(hidden_size_policy, num_actions)\n",
    "\n",
    "        # Fully connected layers for Value (Critic)\n",
    "        self.fc_value = nn.Linear(hidden_size_value, 1)\n",
    "\n",
    "        # Entropy regularization term\n",
    "        self.entropy_weight = 0.01\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        observation,\n",
    "        prev_reward,\n",
    "        prev_action_onehot,\n",
    "        hidden_state_policy,\n",
    "        hidden_state_value,\n",
    "    ):\n",
    "        # Prepare input by concatenating observation, reward, and action\n",
    "        x = torch.cat(\n",
    "            [observation, prev_reward.unsqueeze(-1), prev_action_onehot], dim=-1\n",
    "        )\n",
    "\n",
    "        # LSTM forward pass\n",
    "        policy_out, hidden_state_policy = self.lstm_policy(x, hidden_state_policy)\n",
    "        value_out, hidden_state_value = self.lstm_value(x, hidden_state_value)\n",
    "\n",
    "        # Actor (Policy): output action probabilities\n",
    "        action_probs = F.softmax(self.fc_policy(policy_out[:, -1, :]), dim=-1)\n",
    "\n",
    "        # Critic (Value): output state value estimate\n",
    "        state_value = self.fc_value(value_out[:, -1, :])\n",
    "\n",
    "        return action_probs, state_value, hidden_state_policy, hidden_state_value\n",
    "\n",
    "    def compute_loss(\n",
    "        self, action_probs, state_value, reward, done, prev_state_value, entropy\n",
    "    ):\n",
    "        # Advantage function\n",
    "        advantage = reward - prev_state_value\n",
    "\n",
    "        # Actor loss (policy gradient)\n",
    "        actor_loss = -torch.mean(torch.log(action_probs) * advantage)\n",
    "\n",
    "        # Critic loss (value function)\n",
    "        critic_loss = F.mse_loss(state_value, reward)\n",
    "\n",
    "        # Entropy regularization\n",
    "        entropy_loss = -torch.mean(entropy)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = actor_loss + critic_loss + self.entropy_weight * entropy_loss\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 10  # Example input size (observation, reward, action)\n",
    "num_actions = 2  # Number of possible actions\n",
    "hidden_size = 48  # LSTM hidden size\n",
    "\n",
    "# Initialize the A2C Network\n",
    "net = A2CNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_size_policy=hidden_size,\n",
    "    hidden_size_value=hidden_size,\n",
    "    num_actions=num_actions,\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Function to train the agent\n",
    "def train_agent():\n",
    "    hidden_state_policy = (\n",
    "        torch.zeros(1, 1, hidden_size),\n",
    "        torch.zeros(1, 1, hidden_size),\n",
    "    )\n",
    "    hidden_state_value = (\n",
    "        torch.zeros(1, 1, hidden_size),\n",
    "        torch.zeros(1, 1, hidden_size),\n",
    "    )\n",
    "\n",
    "    for episode in range(1000):  # Simulate for 1000 episodes\n",
    "        observation = torch.randn(1, input_size)  # Example observation\n",
    "        prev_reward = torch.tensor([1.0])  # Example previous reward\n",
    "        prev_action_onehot = torch.randn(\n",
    "            1, num_actions\n",
    "        )  # Example one-hot encoded action from previous step\n",
    "\n",
    "        # Forward pass through the network\n",
    "        action_probs, state_value, hidden_state_policy, hidden_state_value = net(\n",
    "            observation,\n",
    "            prev_reward,\n",
    "            prev_action_onehot,\n",
    "            hidden_state_policy.reshape(-1),\n",
    "            hidden_state_value.squeeze(),\n",
    "        )\n",
    "\n",
    "        # Calculate the entropy (for regularization)\n",
    "        entropy = -torch.sum(action_probs * torch.log(action_probs), dim=-1)\n",
    "\n",
    "        # Get the reward (just for illustration purposes)\n",
    "        reward = torch.tensor([1.0])  # Example reward from environment\n",
    "        done = torch.tensor([False])  # Example terminal state (for simplicity)\n",
    "\n",
    "        # Compute the loss\n",
    "        total_loss = net.compute_loss(\n",
    "            action_probs, state_value, reward, done, state_value, entropy\n",
    "        )\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Episode {episode+1}, Loss: {total_loss.item()}\")\n",
    "\n",
    "\n",
    "# Run training\n",
    "train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# train the model\n",
    "loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i : i + batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i : i + batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Finished epoch {epoch}, latest loss {loss}\")\n",
    "\n",
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def lstm_step(x_t, h_t_prev, c_t_prev, W_i, W_f, W_c, W_o, b_i, b_f, b_c, b_o):\n",
    "    i_t = torch.sigmoid(torch.matmul(W_i, x_t) + torch.matmul(W_i, h_t_prev) + b_i)\n",
    "    f_t = torch.sigmoid(torch.matmul(W_f, x_t) + torch.matmul(W_f, h_t_prev) + b_f)\n",
    "    c_t = f_t * c_t_prev + i_t * torch.tanh(\n",
    "        torch.matmul(W_c, x_t) + torch.matmul(W_c, h_t_prev) + b_c\n",
    "    )\n",
    "    o_t = torch.sigmoid(torch.matmul(W_o, x_t) + torch.matmul(W_o, h_t_prev) + b_o)\n",
    "    h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "    return h_t, c_t\n",
    "\n",
    "\n",
    "# Example initialization (random weights and biases)\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "W_i = torch.randn(hidden_size, input_size, device=device)\n",
    "W_f = torch.randn(hidden_size, input_size, device=device)\n",
    "W_c = torch.randn(hidden_size, input_size, device=device)\n",
    "W_o = torch.randn(hidden_size, input_size, device=device)\n",
    "b_i = torch.randn(hidden_size, device=device)\n",
    "b_f = torch.randn(hidden_size, device=device)\n",
    "b_c = torch.randn(hidden_size, device=device)\n",
    "b_o = torch.randn(hidden_size, device=device)\n",
    "\n",
    "# Example input and previous state\n",
    "x_t = torch.randn(input_size, device=device)\n",
    "h_t_prev = torch.randn(hidden_size, device=device)\n",
    "c_t_prev = torch.randn(hidden_size, device=device)\n",
    "\n",
    "# Compute next LSTM state\n",
    "h_t, c_t = lstm_step(x_t, h_t_prev, c_t_prev, W_i, W_f, W_c, W_o, b_i, b_f, b_c, b_o)\n",
    "print(\"Next Hidden State:\", h_t)\n",
    "print(\"Next Cell State:\", c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Hidden State Shape: torch.Size([5, 20])\n",
      "Next Cell State Shape: torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # A single linear layer for all four gates at once\n",
    "        self.lstm_gate = nn.Linear(input_size + hidden_size, 4 * hidden_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat((x, h_prev), dim=1)\n",
    "\n",
    "        # Compute all gates in a single matrix multiplication\n",
    "        gates = self.lstm_gate(combined)\n",
    "\n",
    "        # Split the output into four parts for input, forget, cell, and output gates\n",
    "        i_t, f_t, c_tilde, o_t = torch.chunk(gates, 4, dim=1)\n",
    "\n",
    "        # Apply activation functions\n",
    "        i_t = self.sigmoid(i_t)  # Input gate\n",
    "        f_t = self.sigmoid(f_t)  # Forget gate\n",
    "        c_tilde = self.tanh(c_tilde)  # Candidate cell state\n",
    "        o_t = self.sigmoid(o_t)  # Output gate\n",
    "\n",
    "        # Compute new cell state and hidden state\n",
    "        c_t = f_t * c_prev + i_t * c_tilde\n",
    "        h_t = o_t * self.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "batch_size = 5\n",
    "\n",
    "lstm_cell = LSTMCell(input_size, hidden_size)\n",
    "\n",
    "# Create random input tensor\n",
    "x = torch.randn(batch_size, input_size)\n",
    "\n",
    "# Initialize previous hidden and cell states with zeros\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "c_prev = torch.zeros(batch_size, hidden_size)\n",
    "\n",
    "# Forward pass\n",
    "h_next, c_next = lstm_cell(x, (h_prev, c_prev))\n",
    "\n",
    "print(\"Next Hidden State Shape:\", h_next.shape)  # Should be (batch_size, hidden_size)\n",
    "print(\"Next Cell State Shape:\", c_next.shape)  # Should be (batch_size, hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
