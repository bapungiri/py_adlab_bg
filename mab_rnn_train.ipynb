{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1f6370",
   "metadata": {},
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e02877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from banditpy.models import BanditTrainer2Arm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def adaptive_hyperparameter_search():\n",
    "    \"\"\"Adaptive search that learns from previous results\"\"\"\n",
    "\n",
    "    # Start with educated guesses\n",
    "    candidates = [\n",
    "        {\"lr\": 1e-4, \"beta_entropy\": 0.1, \"beta_value\": 0.1, \"hidden_size\": 48},\n",
    "        {\"lr\": 5e-4, \"beta_entropy\": 0.15, \"beta_value\": 0.1, \"hidden_size\": 48},\n",
    "        {\"lr\": 1e-4, \"beta_entropy\": 0.2, \"beta_value\": 0.1, \"hidden_size\": 48},\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for round_num in range(3):  # 3 rounds of refinement\n",
    "        print(f\"\\n--- Round {round_num + 1} ---\")\n",
    "\n",
    "        round_results = []\n",
    "        for i, params in enumerate(candidates):\n",
    "            print(f\"Testing: {params}\")\n",
    "\n",
    "            bt = BanditTrainer2Arm(**params, model_path=f\"adaptive_{round_num}_{i}.pt\")\n",
    "            bt.train(mode=\"U\", n_sessions=2500, n_trials=200)\n",
    "\n",
    "            metrics = bt.comprehensive_evaluation()\n",
    "\n",
    "            result = params.copy()\n",
    "            result.update(metrics)\n",
    "            result[\"round\"] = round_num\n",
    "            round_results.append(result)\n",
    "            results.append(result)\n",
    "\n",
    "        # Find best and generate new candidates around it\n",
    "        round_df = pd.DataFrame(round_results)\n",
    "        best = round_df.loc[round_df[\"composite_score\"].idxmax()]\n",
    "\n",
    "        # Generate new candidates around best\n",
    "        candidates = generate_candidates_around_best(best)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def generate_candidates_around_best(best_params):\n",
    "    \"\"\"Generate new candidates around best parameters\"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Variations around best\n",
    "    variations = [\n",
    "        {\"lr_mult\": 0.7, \"entropy_mult\": 0.8, \"value_mult\": 1.0},\n",
    "        {\"lr_mult\": 1.0, \"entropy_mult\": 1.2, \"value_mult\": 0.8},\n",
    "        {\"lr_mult\": 1.3, \"entropy_mult\": 1.0, \"value_mult\": 1.2},\n",
    "        {\"lr_mult\": 0.8, \"entropy_mult\": 1.5, \"value_mult\": 1.0},\n",
    "    ]\n",
    "\n",
    "    for var in variations:\n",
    "        candidate = {\n",
    "            \"lr\": best_params[\"lr\"] * var[\"lr_mult\"],\n",
    "            \"beta_entropy\": best_params[\"beta_entropy\"] * var[\"entropy_mult\"],\n",
    "            \"beta_value\": best_params[\"beta_value\"] * var[\"value_mult\"],\n",
    "            \"hidden_size\": int(best_params[\"hidden_size\"]),\n",
    "        }\n",
    "        candidates.append(candidate)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dac95",
   "metadata": {},
   "source": [
    "### Beta search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40433931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mab_subjects\n",
    "import pandas as pd\n",
    "from banditpy.models import BanditTrainer2Arm\n",
    "from banditpy.utils import generate_probs_2arm\n",
    "from pathlib import Path\n",
    "from banditpy.core import Bandit2Arm\n",
    "\n",
    "n_train_sessions = 30000\n",
    "n_test_sessions = 200\n",
    "\n",
    "probs = np.array([0.2, 0.3, 0.4, 0.6, 0.7, 0.8])\n",
    "unstruc_probs_train, struc_probs_train = generate_probs_2arm(\n",
    "    probs, N=n_train_sessions, frac_impurity=0.16\n",
    ")\n",
    "unstruc_probs_test, struc_probs_test = generate_probs_2arm(\n",
    "    probs, N=n_test_sessions, frac_impurity=0.16\n",
    ")\n",
    "\n",
    "basepath = Path(\"D:/Data/mab/rnn_models/beta_search\")\n",
    "beta_entropys = np.linspace(0.02, 0.1, 30)\n",
    "beta_values = np.linspace(0.02, 0.1, 30)\n",
    "lr = 0.00004\n",
    "gamma = 0.9\n",
    "\n",
    "search_df = []\n",
    "for i1, be in enumerate(beta_entropys):\n",
    "    for i2, bv in enumerate(beta_values):\n",
    "\n",
    "        # ------ Structured network ----------\n",
    "        b2a_s = BanditTrainer2Arm(\n",
    "            lr=lr,\n",
    "            gamma=gamma,\n",
    "            beta_entropy=be,\n",
    "            beta_value=bv,\n",
    "            device=\"cpu\",\n",
    "            model_path=basepath / f\"beta_search_structured.pt\",\n",
    "        )\n",
    "        b2a_s.train(\n",
    "            n_sessions=n_train_sessions,\n",
    "            mode=struc_probs_train,\n",
    "            save_model=False,\n",
    "            return_df=False,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "        dfs = b2a_s.evaluate(n_sessions=n_test_sessions, mode=struc_probs_test)\n",
    "        task_s = Bandit2Arm.from_df(\n",
    "            df=dfs,\n",
    "            probs=[\"arm1_reward_prob\", \"arm2_reward_prob\"],\n",
    "            choices=\"chosen_action\",\n",
    "            rewards=\"reward\",\n",
    "            session_ids=\"session_id\",\n",
    "        )\n",
    "        perf_s = task_s.get_optimal_choice_probability()\n",
    "        final_perf_s = perf_s[-5:].mean()\n",
    "\n",
    "        # ------ Untructured network ----------\n",
    "        b2a_u = BanditTrainer2Arm(\n",
    "            lr=lr,\n",
    "            gamma=gamma,\n",
    "            beta_entropy=be,\n",
    "            beta_value=bv,\n",
    "            device=\"cpu\",\n",
    "            model_path=basepath / f\"beta_search_unstructured.pt\",\n",
    "        )\n",
    "        b2a_u.train(\n",
    "            n_sessions=n_train_sessions,\n",
    "            mode=unstruc_probs_train,\n",
    "            save_model=False,\n",
    "            return_df=False,\n",
    "            progress_bar=False,\n",
    "        )\n",
    "        dfu = b2a_u.evaluate(n_sessions=n_test_sessions, mode=unstruc_probs_test)\n",
    "        task_u = Bandit2Arm.from_df(\n",
    "            df=dfu,\n",
    "            probs=[\"arm1_reward_prob\", \"arm2_reward_prob\"],\n",
    "            choices=\"chosen_action\",\n",
    "            rewards=\"reward\",\n",
    "            session_ids=\"session_id\",\n",
    "        )\n",
    "        perf_u = task_u.get_optimal_choice_probability()\n",
    "        final_perf_u = perf_u[-5:].mean()\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            dict(\n",
    "                beta_entropy=be,\n",
    "                beta_value=bv,\n",
    "                final_perf_s=final_perf_s,\n",
    "                final_perf_u=final_perf_u,\n",
    "            ),\n",
    "            index=[0],\n",
    "        )\n",
    "        search_df.append(df)\n",
    "\n",
    "search_df = pd.concat(search_df, ignore_index=True)\n",
    "# mab_subjects.GroupData().save(search_df, \"beta_search_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0362e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_probs(self, mode, N, low=0, high=1, decimals=1):\n",
    "    \"\"\"\n",
    "    Generates reward probabilities for the two arms for a session.\n",
    "    \"\"\"\n",
    "    if isinstance(mode, np.ndarray):\n",
    "        if mode.shape == (2,):\n",
    "            p_arm1 = np.ones(N) * mode[0]\n",
    "            p_arm2 = np.ones(N) * mode[1]\n",
    "        elif mode.shape == (N, 2):\n",
    "            p_arm1, p_arm2 = mode[:, 0], mode[:, 1]\n",
    "\n",
    "        self.train_type = \"CustomProbabilities\"\n",
    "\n",
    "    elif isinstance(mode, str):\n",
    "        match mode:\n",
    "            case \"Structured\" | \"Struc\" | \"S\":\n",
    "                p_arm1 = np.round(\n",
    "                    np.random.uniform(low, high, size=N), decimals=decimals\n",
    "                )\n",
    "                p_arm2 = np.round(1.0 - p_arm1, decimals=decimals)\n",
    "\n",
    "                self.train_type = \"Structured\"\n",
    "\n",
    "            case \"Unstructured\" | \"Unstruc\" | \"U\":\n",
    "                p_arm1 = np.round(\n",
    "                    np.random.uniform(low, high, size=N), decimals=decimals\n",
    "                )\n",
    "                p_arm2 = np.round(\n",
    "                    np.random.uniform(low, high, size=N), decimals=decimals\n",
    "                )\n",
    "                self.train_type = \"Unstructured\"\n",
    "\n",
    "    elif isinstance(mode, list):\n",
    "        assert len(mode) == 2, \"Reward probabilities list must have exactly 2 elements.\"\n",
    "        p_arm1 = mode[0] * np.ones(N)\n",
    "        p_arm2 = mode[1] * np.ones(N)\n",
    "        self.train_type = \"CustomProbabilities\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid mode. Use 'Structured'/'Struc'/'S', 'Unstructured'/'Unstruc'/'U', or a list of probabilities of length 2, or a numpy array of shape (2,) or (N, 2).\"\n",
    "        )\n",
    "\n",
    "    print(p_arm1)\n",
    "    # Ensure probabilities are valid\n",
    "    if np.all(p_arm1 <= 1) and np.all(p_arm2 <= 1):\n",
    "        raise ValueError(\"Reward probabilities must be between 0 and 1.\")\n",
    "\n",
    "    return np.array([p_arm1, p_arm2]).T  # Index 0 for arm 1, index 1 for arm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982da917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "probs = np.array([0.2, 0.3, 0.4, 0.6, 0.7, 0.8])\n",
    "unstruc_probs, struc_probs = generate_probs_2arm(\n",
    "    probs, N=n_train_sessions, frac_impurity=0.16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795052e0",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from banditpy.models import BanditTrainer2Arm\n",
    "from pathlib import Path\n",
    "\n",
    "basepath = Path(\"D:/Data/mab/rnn_models/probs_1decimals\")\n",
    "prob_kwargs = dict(high=0.91, low=0.1, decimals=1)\n",
    "\n",
    "n_sessions = 30000\n",
    "\n",
    "for i in range(10):\n",
    "    # ------ Structured network ----------\n",
    "    b2a_s = BanditTrainer2Arm(model_path=basepath / f\"structured_2arm_model{i}.pt\")\n",
    "    b2a_s.train(n_sessions=n_sessions, mode=\"Struc\", return_df=False, **prob_kwargs)\n",
    "    b2a_s.save_model()\n",
    "\n",
    "    # ------ Untructured network ----------\n",
    "    b2a_u = BanditTrainer2Arm(model_path=basepath / f\"unstructured_2arm_model{i}.pt\")\n",
    "    b2a_u.train(n_sessions=n_sessions, mode=\"Unstruc\", return_df=False, **prob_kwargs)\n",
    "    b2a_u.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724ed3c",
   "metadata": {},
   "source": [
    "### Train Network with custom probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from banditpy.models import BanditTrainer2Arm\n",
    "from banditpy.utils import generate_probs_2arm\n",
    "from pathlib import Path\n",
    "\n",
    "n_sessions = 30000\n",
    "\n",
    "probs = np.array([0.2, 0.3, 0.4, 0.6, 0.7, 0.8])\n",
    "unstruc_probs, struc_probs = generate_probs_2arm(\n",
    "    probs, N=n_sessions, frac_impurity=0.16\n",
    ")\n",
    "\n",
    "basepath = Path(\"D:/Data/mab/rnn_models/Train1dec_0.16impure_345reset/\")\n",
    "\n",
    "for i in range(10):\n",
    "    # ------ Structured network ----------\n",
    "    b2a_s = BanditTrainer2Arm(\n",
    "        model_path=basepath / f\"structured_2arm_model{i}.pt\", device=\"cpu\"\n",
    "    )\n",
    "    b2a_s.train(n_sessions=n_sessions, mode=struc_probs, return_df=False)\n",
    "    b2a_s.save_model()\n",
    "\n",
    "    # ------ Untructured network ----------\n",
    "    b2a_u = BanditTrainer2Arm(\n",
    "        model_path=basepath / f\"unstructured_2arm_model{i}.pt\", device=\"cpu\"\n",
    "    )\n",
    "    b2a_u.train(n_sessions=n_sessions, mode=unstruc_probs, return_df=False)\n",
    "    b2a_u.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
