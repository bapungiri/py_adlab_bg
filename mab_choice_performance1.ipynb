{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646ce9e6",
   "metadata": {},
   "source": [
    "### Performance across sessions binned\n",
    "- Calculate performance across sessions and bin sessions into roughly 10 sessions per bin. This one also calculates \"struc_in_unstruc\" sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d96e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mab_subjects\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess + mab_subjects.struc.allsess\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "    mab = exp.b2a.filter_by_trials(min_trials=100, clip_max=150)\n",
    "    perf = mab.get_optimal_choice_probability(bin_size=10)\n",
    "\n",
    "    df = pd.DataFrame(data=perf, columns=np.arange(perf.shape[1]) + 1)\n",
    "    df[\"session_bin\"] = np.arange(perf.shape[0]) + 1\n",
    "    df = df.melt(id_vars=\"session_bin\", var_name=\"trial_id\", value_name=\"perf\")\n",
    "    df.sort_values(by=[\"session_bin\", \"trial_id\"], inplace=True)\n",
    "\n",
    "    df[\"name\"] = exp.sub_name\n",
    "    df[\"grp\"] = \"struc\" if mab.is_structured else \"unstruc\"\n",
    "\n",
    "    perf_df.append(df)\n",
    "\n",
    "    if ~mab.is_structured:\n",
    "        mab2 = exp.b2a.filter_by_trials(min_trials=100, clip_max=150)\n",
    "        session_prob_sum = mab2.probs[mab2.is_session_start.astype(bool)].sum(axis=1)\n",
    "        good_sessions = mab2.sessions[session_prob_sum == 1]\n",
    "        assert np.all(good_sessions)\n",
    "        mab2 = mab2.filter_by_session_id(good_sessions)\n",
    "\n",
    "        perf = mab2.get_optimal_choice_probability(bin_size=10)\n",
    "\n",
    "        df2 = pd.DataFrame(data=perf, columns=np.arange(perf.shape[1]) + 1)\n",
    "        df2[\"session_bin\"] = np.arange(perf.shape[0]) + 1\n",
    "        df2 = df2.melt(id_vars=\"session_bin\", var_name=\"trial_id\", value_name=\"perf\")\n",
    "        df2.sort_values(by=[\"session_bin\", \"trial_id\"], inplace=True)\n",
    "\n",
    "        df2[\"name\"] = exp.sub_name\n",
    "        df2[\"grp\"] = \"struc_in_unstruc\"\n",
    "        perf_df.append(df2)\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(perf_df, \"perf_100min150max_10bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "from statannotations.Annotator import Annotator\n",
    "from statplot_utils import stat_kw\n",
    "\n",
    "fig = plotting.Fig(1, 3, size=(11, 3), num=1)\n",
    "\n",
    "grpdata = mab_subjects.GroupData()\n",
    "df = grpdata.perf_100min150max_10bin\n",
    "df1 = df[((df[\"session_bin\"] > 30) & (df[\"grp\"] == \"unstruc\"))]\n",
    "df1[\"grp\"] = \"unstruc_late\"\n",
    "df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "# ax.axhline(0, color=\"gray\", lw=0.8, zorder=0)\n",
    "hue_order = [\"unstruc\", \"struc\", \"struc_in_unstruc\", \"unstruc_late\"]\n",
    "plot_kw = dict(data=df, x=\"trial_id\", y=\"perf\", hue=\"grp\", hue_order=hue_order, ax=ax)\n",
    "sns.lineplot(\n",
    "    palette=[\"#f77189\", \"#36ada4\", \"#a48cf4\", \"#f7c94a\"],\n",
    "    # edgecolor=\"white\",\n",
    "    # facecolor=(0, 0, 0, 0),\n",
    "    # alpha=0.4,\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    "    errorbar=\"se\",\n",
    "    **plot_kw,\n",
    ")\n",
    "\n",
    "\n",
    "# orders = [\"unstruc\", \"struc\"]\n",
    "# pairs = [((\"unstruc\"), (\"struc\"))]\n",
    "# annotator = Annotator(pairs=pairs, order=orders, **plot_kw)\n",
    "# annotator.configure(test=\"Kruskal\", **stat_kw, color=\"k\", verbose=True)\n",
    "# annotator.apply_and_annotate()\n",
    "# annotator.reset_configuration()\n",
    "# ax.grid(True)\n",
    "ax.set_title(\"Performance\")\n",
    "ax.set_ylabel(\"Performance\")\n",
    "ax.set_ylim(0.45, 1)\n",
    "ax.set_xticks([1, 50, 100, 150])\n",
    "# ax.legend(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddece52",
   "metadata": {},
   "source": [
    "### Performance in all, easy, and hard sessions\n",
    "- Comparing Unstruc and Struc where the difference in probability is more than 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mab_subjects\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess + mab_subjects.struc.allsess\n",
    "trial_filter = dict(min_trials=100, clip_max=100)\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "    task = exp.b2a.filter_by_trials(**trial_filter).filter_by_deltaprob(\n",
    "        delta_min=0.05, delta_max=None\n",
    "    )\n",
    "    mab_easy = task.filter_by_deltaprob(delta_min=0.4)\n",
    "    mab_hard = task.filter_by_deltaprob(delta_min=0.1, delta_max=0.35)\n",
    "\n",
    "    perf = task.get_optimal_choice_probability()\n",
    "    perf_easy = mab_easy.get_optimal_choice_probability()\n",
    "    perf_hard = mab_hard.get_optimal_choice_probability()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            trial_id=np.arange(perf.size) + 1,\n",
    "            perf=perf,\n",
    "            perf_easy=perf_easy,\n",
    "            perf_hard=perf_hard,\n",
    "            name=exp.sub_name,\n",
    "            grp=\"struc\" if task.is_structured else \"unstruc\",\n",
    "            first_experience=True if \"Exp1\" in exp.sub_name else False,\n",
    "        )\n",
    "    )\n",
    "    perf_df.append(df)\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(perf_df, \"perf_difficulty_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "from mab_colors import colors_2arm\n",
    "from statplotannot.plots import SeabornPlotter, fix_legend\n",
    "\n",
    "fig = plotting.Fig(5, 3, num=1, fontsize=10)\n",
    "\n",
    "grpdata = mab_subjects.GroupData()\n",
    "df = grpdata.perf_difficulty_level\n",
    "df = df[df[\"first_experience\"] == True]\n",
    "\n",
    "# ax = fig.subplot(fig.gs[0])\n",
    "hue_order = [\"unstruc\", \"struc\"]\n",
    "linestyles = [\"-\", \"--\", \":\"]\n",
    "titles = [\n",
    "    \"All permutations\",\n",
    "    \"Easy\\n(DeltaP>=40)\",\n",
    "    \"Hard\\n(DeltaP<=30)\",\n",
    "]\n",
    "\n",
    "for i, y in enumerate([\"perf\", \"perf_easy\", \"perf_hard\"]):\n",
    "\n",
    "    ax = fig.subplot(fig.gs[i])\n",
    "    plot_kw = dict(data=df, x=\"trial_id\", y=y, hue=\"grp\", hue_order=hue_order, ax=ax)\n",
    "    sns.lineplot(\n",
    "        palette=colors_2arm(),\n",
    "        lw=1.1,\n",
    "        # ls=linestyles[i],\n",
    "        ls=\"-\",\n",
    "        err_kws=dict(edgecolor=\"none\"),\n",
    "        errorbar=\"se\",\n",
    "        **plot_kw,\n",
    "    )\n",
    "    ax.set_ylim(0.45, 1)\n",
    "    fix_legend(ax, only_labels=True, fw=\"bold\", fs=10)\n",
    "    ax.grid(axis=\"y\", zorder=-1, alpha=0.5)\n",
    "    ax.set_ylabel(\"Pr(Optimal Choice)\")\n",
    "    ax.set_xticks([1, 25, 50, 75, 100])\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "# ax.legend(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb8c46",
   "metadata": {},
   "source": [
    "### Lesion: Performance matrix\n",
    "- Bins are represented by probability combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mab_subjects\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess + mab_subjects.struc.allsess\n",
    "# exps = mab_subjects.unstruc.Grump\n",
    "\n",
    "prob_perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "    task = exp.b2a\n",
    "    # print(task.probs_corr)\n",
    "    # task.auto_block_window_ids()\n",
    "    # mask = task.block_ids == 1\n",
    "    # task = task._filtered(mask).filter_by_trials(100, 100)\n",
    "\n",
    "    perf_mat, unique_probs = task.get_performance_prob_grid(n_last_trials=5)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"probs\": [unique_probs],\n",
    "            \"perf_mat\": [perf_mat],\n",
    "            \"name\": exp.sub_name,\n",
    "            \"grp\": exp.group_tag,\n",
    "            \"lesion\": exp.lesion_tag,\n",
    "            \"dataset\": exp.data_tag,\n",
    "        }\n",
    "    )\n",
    "    df[\"name\"] = exp.sub_name\n",
    "    df[\"grp\"] = exp.group_tag\n",
    "\n",
    "    prob_perf_df.append(df)\n",
    "\n",
    "prob_perf_df = pd.concat(prob_perf_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(prob_perf_df, \"perf_probability_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b355589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import Fig\n",
    "import seaborn as sns\n",
    "from scipy.stats import binned_statistic_2d\n",
    "from mab_colors import colors_2arm\n",
    "from statplotannot.plots import fix_legend\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from palettable.scientific.sequential import GrayC_7\n",
    "\n",
    "fig = Fig(5, 3, size=(8.5, 11), num=1, fontsize=12)\n",
    "\n",
    "df = mab_subjects.GroupData().perf_probability_matrix.latest\n",
    "df = df[df[\"lesion\"] == \"pre_lesion\"]\n",
    "for g, grp in enumerate([\"struc\", \"unstruc\"]):\n",
    "    df_grp = df[df[\"grp\"] == grp]\n",
    "    perf_mean = df_grp[\"perf_mat\"].mean()\n",
    "    # perf_mean = gaussian_filter(perf_mean, sigma=0.1)\n",
    "    perf_mean = np.tril(perf_mean, k=-1)\n",
    "    mask = np.triu(np.ones_like(perf_mean, dtype=bool), k=0)\n",
    "\n",
    "    perf_mean[mask] = np.nan\n",
    "\n",
    "    ax = fig.subplot(fig.gs[g])\n",
    "\n",
    "    im = ax.pcolormesh(\n",
    "        perf_mean.T,\n",
    "        # cmap=GrayC_7.mpl_colormap,\n",
    "        cmap=\"Blues\",\n",
    "        shading=\"auto\",\n",
    "        vmin=0.5,\n",
    "        vmax=1,\n",
    "    )\n",
    "    ticks = np.arange(0, 8) + 0.5\n",
    "    ax.set_xticks(ticks, [10, 20, 30, 40, 60, 70, 80, 90])\n",
    "    ax.set_yticks(ticks, [10, 20, 30, 40, 60, 70, 80, 90])\n",
    "    ax.set_xlim(1, 8)\n",
    "    ax.set_ylim(0, 7)\n",
    "    ax.spines[\"right\"].set_visible(True)\n",
    "    ax.spines[\"top\"].set_visible(True)\n",
    "    ax.set_xlabel(\"Higher reward probability\")\n",
    "    ax.set_ylabel(\"Lower reward probability\")\n",
    "\n",
    "    cb = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "    cb.set_label(\"Performance\")\n",
    "\n",
    "\n",
    "# ax.legend_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfccbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81088217",
   "metadata": {},
   "source": [
    "### Entropy of choices in equal probability arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mab_subjects\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess\n",
    "\n",
    "entropy_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "    task = exp.b2a.filter_by_trials(min_trials=100, clip_max=100).filter_by_deltaprob(\n",
    "        delta_min=0, delta_max=0\n",
    "    )\n",
    "    entropy = task.get_choice_entropy()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"trial_id\": np.arange(len(entropy)) + 1,\n",
    "            \"entropy\": entropy,\n",
    "            \"name\": exp.sub_name,\n",
    "            \"grp\": \"struc\" if task.is_structured else \"unstruc\",\n",
    "            \"first_experience\": True if \"Exp1\" in exp.sub_name else False,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    entropy_df.append(df)\n",
    "\n",
    "entropy_df = pd.concat(entropy_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(entropy_df, \"entropy_equal_probs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mab_subjects\n",
    "from neuropy import plotting\n",
    "from mab_colors import colors_2arm\n",
    "\n",
    "df = mab_subjects.GroupData().entropy_equal_probs\n",
    "df = df[df[\"first_experience\"] == True]\n",
    "\n",
    "fig = plotting.Fig(1, 3, size=(11, 3), num=1)\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.lineplot(data=df, x=\"trial_id\", y=\"entropy\", color=colors_2arm()[0], errorbar=\"se\")\n",
    "ax.set_title(\"Entropy of choosing between equal probability arms\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Entropy\")\n",
    "# ax.legend_.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835dcc0",
   "metadata": {},
   "source": [
    "### Impure environments individual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d32611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from banditpy.plots import plot_trial_by_trial_2Arm\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess + mab_subjects.struc.allsess\n",
    "\n",
    "fig = plotting.Fig(8, 6)\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "\n",
    "    task = exp.b2a\n",
    "    probs_corr = task.probs_corr\n",
    "\n",
    "    if probs_corr < -0.5:\n",
    "        grp = \"struc\"\n",
    "    else:\n",
    "        grp = \"unstruc\"\n",
    "\n",
    "    H, xedges, yedges = task.get_prob_hist_2d(stat=\"prop\")\n",
    "    # choices[choices == 1] = 2\n",
    "    # choices[task.choices == 2] = 1\n",
    "    # task.choices = choices\n",
    "\n",
    "    perf = task.filter_by_trials(\n",
    "        min_trials=100, clip_max=100\n",
    "    ).get_optimal_choice_probability()\n",
    "\n",
    "    ax = fig.subplot(fig.gs[3 * i])\n",
    "    ax.plot(perf, color=\"k\")\n",
    "    # task.plot_trial_by_trial(ax=ax)\n",
    "    ax.set_ylim(0.4, 0.9)\n",
    "    ax.set_xlabel(\"Trial_id\")\n",
    "    ax.set_ylabel(\"Choice (High)\")\n",
    "    ax.set_title(f\"{exp.sub_name}'s performance\")\n",
    "\n",
    "    ax2 = fig.subplot(fig.gs[3 * i + 1])\n",
    "    cplot = ax2.pcolormesh(\n",
    "        xedges,\n",
    "        yedges,\n",
    "        H.T,\n",
    "        cmap=\"hot\",\n",
    "        vmin=0,\n",
    "        # vmax=14,\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "    cb = plt.colorbar(cplot, ax=ax2, shrink=0.5)\n",
    "    # ax2.imshow(prob_mat)\n",
    "    ax2.set_xlabel(\"Prob1\")\n",
    "    ax2.set_ylabel(\"Prob2\")\n",
    "    ax2.set_title(f\"{exp.sub_name}'s probability combinations\")\n",
    "    # ax2.set_xticks([0.2, 0.3, 0.4, 0.6, 0.7, 0.8])\n",
    "    # ax2.set_yticks([0.2, 0.3, 0.4, 0.6, 0.7, 0.8])\n",
    "    cb.set_label(\"Counts\")\n",
    "\n",
    "    ax3 = fig.subplot(fig.gs[3 * i + 2])\n",
    "    h, bins = task.get_trials_hist()\n",
    "\n",
    "    ax3.plot(bins, h, color=\"k\")\n",
    "    ax3.set_xlim(0, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80eba3",
   "metadata": {},
   "source": [
    "###  Impure: Overall performance\n",
    "- Compares unstruc and struc across all combinations, pure combinations, and impure combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164be1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from banditpy.plots import plot_trial_by_trial_2Arm\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "exps = mab_subjects.mostly_unstruc.allsess + mab_subjects.mostly_struc.allsess\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "\n",
    "    task = exp.b2a\n",
    "    probs_corr = task.probs_corr\n",
    "    print(probs_corr)\n",
    "\n",
    "    task_filt = task.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    perf_overall = task_filt.get_optimal_choice_probability()\n",
    "    probs_all = task_filt.probs\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"trial_id\"] = np.arange(perf_overall.shape[0]) + 1\n",
    "    df[\"All combinations\"] = perf_overall\n",
    "\n",
    "    if probs_corr < -0.5:\n",
    "        grp = \"struc\"\n",
    "        dependent_mask = probs_all.sum(axis=1) == 1.0\n",
    "        independent_mask = ~dependent_mask\n",
    "\n",
    "        perf_pure = task_filt._filtered(dependent_mask).get_optimal_choice_probability()\n",
    "\n",
    "        perf_impure = task_filt._filtered(\n",
    "            independent_mask\n",
    "        ).get_optimal_choice_probability()\n",
    "    else:\n",
    "        grp = \"unstruc\"\n",
    "        dependent_mask = probs_all.sum(axis=1) == 1.0\n",
    "        independent_mask = ~dependent_mask\n",
    "\n",
    "        perf_impure = task_filt._filtered(\n",
    "            dependent_mask\n",
    "        ).get_optimal_choice_probability()\n",
    "\n",
    "        perf_pure = task_filt._filtered(\n",
    "            independent_mask\n",
    "        ).get_optimal_choice_probability()\n",
    "\n",
    "    df[\"Pure combinations\"] = perf_pure\n",
    "    df[\"Impure combinations\"] = perf_impure\n",
    "    df[\"name\"] = exp.sub_name\n",
    "    df[\"grp\"] = grp\n",
    "    perf_df.append(df)\n",
    "\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "# mab_subjects.GroupData().save(perf_df, \"perf_100min150max_10bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f51961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statplotannot.plots import SeabornPlotter, fix_legend\n",
    "from mab_colors import colors_2arm\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "\n",
    "fig = plotting.Fig(3, 3, size=(8.5, 6), fontsize=10)\n",
    "\n",
    "for i, y in enumerate([\"All combinations\", \"Pure combinations\", \"Impure combinations\"]):\n",
    "    ax = fig.subplot(fig.gs[i])\n",
    "    sns.lineplot(\n",
    "        data=perf_df,\n",
    "        x=\"trial_id\",\n",
    "        y=y,\n",
    "        hue=\"grp\",\n",
    "        palette=colors_2arm(),\n",
    "        errorbar=\"se\",\n",
    "    )\n",
    "    fix_legend(ax)\n",
    "    ax.set_ylim(0.4, 0.85)\n",
    "    ax.set_ylabel(\"P(High)\")\n",
    "    ax.set_title(y)\n",
    "    ax.grid(axis=\"y\", zorder=-1, alpha=0.5)\n",
    "\n",
    "\n",
    "for i, grp in enumerate([\"unstruc\", \"struc\"]):\n",
    "    ax = fig.subplot(fig.gs[1, i])\n",
    "    df_new = perf_df[perf_df[\"grp\"] == grp]\n",
    "    sns.lineplot(\n",
    "        data=df_new,\n",
    "        x=\"trial_id\",\n",
    "        y=\"All combinations\",\n",
    "        ax=ax,\n",
    "        hue=\"grp\",\n",
    "        palette=[colors_2arm(1)[i]],\n",
    "        errorbar=None,\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=df_new,\n",
    "        x=\"trial_id\",\n",
    "        y=\"Pure combinations\",\n",
    "        ax=ax,\n",
    "        hue=\"grp\",\n",
    "        palette=[colors_2arm(0.6)[i]],\n",
    "        errorbar=None,\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=df_new,\n",
    "        x=\"trial_id\",\n",
    "        y=\"Impure combinations\",\n",
    "        ax=ax,\n",
    "        hue=\"grp\",\n",
    "        palette=[colors_2arm(1.4)[i]],\n",
    "        errorbar=None,\n",
    "    )\n",
    "    fix_legend(ax)\n",
    "    ax.set_ylim(0.4, 0.85)\n",
    "    ax.set_ylabel(\"P(High)\")\n",
    "    ax.set_title(f\"{grp} group\")\n",
    "    ax.grid(axis=\"y\", zorder=-1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0337a5",
   "metadata": {},
   "source": [
    "### Lesion: Overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543c7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggro\n",
      "Aggro\n",
      "Auroma\n",
      "Torres\n",
      "Debruyne\n",
      "Kompany\n",
      "GrumpExp1Unstructured\n",
      "Bewilderbeast\n",
      "Aguero\n",
      "Aguero\n",
      "Sterling\n",
      "Phil\n",
      "Rodri\n",
      "gronckle\n",
      "ToothlessExp1Structured\n",
      "BuffalordExp1Structured\n",
      "[GroupData] Saved: perf_AAdataset_Block1_20251207_160907.npy\n",
      "Deleted old version: perf_AAdataset_Block1_20251205_184242.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'perf_AAdataset_Block1_20251207_160907.npy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess + mab_subjects.struc.allsess\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print(exp.sub_name)\n",
    "\n",
    "    task = exp.b2a\n",
    "    # task.auto_block_window_ids()\n",
    "    # mask = task.block_ids == 1\n",
    "    # task = task._filtered(mask)\n",
    "\n",
    "    task = task.filter_by_trials(min_trials=100, clip_max=100).filter_by_deltaprob(\n",
    "        delta_min=0.05\n",
    "    )\n",
    "\n",
    "    perf_overall = task.get_optimal_choice_probability()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"trial_id\"] = np.arange(perf_overall.shape[0]) + 1\n",
    "    df[\"performance\"] = gaussian_filter1d(perf_overall, sigma=1)\n",
    "    df[\"name\"] = exp.sub_name\n",
    "    df[\"grp\"] = exp.group_tag\n",
    "    df[\"dataset\"] = exp.data_tag\n",
    "    df[\"lesion\"] = exp.lesion_tag\n",
    "\n",
    "    perf_df.append(df)\n",
    "\n",
    "    if exp.group_tag == \"unstruc\":\n",
    "        dependent_mask = (task.probs.sum(axis=1) > 0.98) & (\n",
    "            task.probs.sum(axis=1) < 1.01\n",
    "        )\n",
    "        task_dep = task._filtered(dependent_mask)\n",
    "        perf_dep = task_dep.get_optimal_choice_probability()\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"trial_id\"] = np.arange(perf_overall.shape[0]) + 1\n",
    "        df[\"performance\"] = gaussian_filter1d(perf_dep, sigma=1)\n",
    "        df[\"name\"] = exp.sub_name\n",
    "        df[\"grp\"] = \"struc_in_unstruc\"\n",
    "        df[\"dataset\"] = exp.data_tag\n",
    "        df[\"lesion\"] = exp.lesion_tag\n",
    "\n",
    "        perf_df.append(df)\n",
    "\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(perf_df, \"perf_AAdataset_Block1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statplotannot.plots import SeabornPlotter, fix_legend\n",
    "from mab_colors import colors_2arm\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "\n",
    "fig = plotting.Fig(3, 3, size=(8.5, 6), fontsize=10)\n",
    "\n",
    "perf_df = mab_subjects.GroupData().perf_AAdataset_Block1.latest\n",
    "# perf_df = perf_df[perf_df[\"dataset\"] == \"ACdataset\"]\n",
    "df1 = perf_df[perf_df[\"lesion\"].isin([\"pre_lesion\"])]\n",
    "df2 = perf_df[perf_df[\"lesion\"].isin([\"pre_lesion\", \"post_lesion_OFC\"])]\n",
    "df3 = perf_df[perf_df[\"lesion\"].isin([\"pre_lesion\", \"naive_lesion_OFC\"])]\n",
    "\n",
    "for d, df in enumerate([df1]):\n",
    "\n",
    "    df[\"grp_new\"] = df[\"grp\"] + \"_\" + df[\"lesion\"]\n",
    "\n",
    "    ax = fig.subplot(fig.gs[d])\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"trial_id\",\n",
    "        y=y,\n",
    "        hue=\"grp_new\",\n",
    "        # palette=colors_2arm(),\n",
    "        palette=[\"orange\", \"green\"],\n",
    "        hue_order=[\"unstruc\", \"struc\"],\n",
    "        errorbar=\"se\",\n",
    "    )\n",
    "    fix_legend(ax)\n",
    "    ax.set_ylim(0.4, 1)\n",
    "    ax.set_ylabel(\"P(High)\")\n",
    "    ax.set_title(y)\n",
    "    ax.grid(axis=\"y\", zorder=-1, alpha=0.5)\n",
    "\n",
    "for d1, df in enumerate([df2, df3]):\n",
    "\n",
    "    df_unstruc = df[df[\"grp\"] == \"unstruc\"]\n",
    "    df_struc = df[df[\"grp\"] == \"struc\"]\n",
    "    colors = [\"orange\", \"green\"]\n",
    "\n",
    "    for d2, df_temp in enumerate([df_unstruc, df_struc]):\n",
    "        df_temp[\"grp_new\"] = df_temp[\"grp\"] + \"_\" + df_temp[\"lesion\"]\n",
    "\n",
    "        ax = fig.subplot(fig.gs[d1 + 1, d2])\n",
    "        sns.lineplot(\n",
    "            data=df_temp,\n",
    "            x=\"trial_id\",\n",
    "            y=y,\n",
    "            hue=\"grp_new\",\n",
    "            # palette=colors_2arm(),\n",
    "            palette=[colors[d2], \"gray\"],\n",
    "            # hue_order=[\"unstruc_pre_lesion\", \"struc_pre_lesion\"],\n",
    "            errorbar=\"se\",\n",
    "        )\n",
    "        fix_legend(ax)\n",
    "        ax.set_ylim(0.4, 1)\n",
    "        ax.set_ylabel(\"P(High)\")\n",
    "        ax.set_title(y)\n",
    "        ax.grid(axis=\"y\", zorder=-1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a462ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.fig.suptitle(\"Aarushi dataset only - Block 1 performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b67f1c",
   "metadata": {},
   "source": [
    "### Aarushi's code for performance matrix/curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b60dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI matrix for diff rew prob combinations - Unstr animals\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "# Unstructured animals: paths\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "unstructured_paths_unsubsetted = {\n",
    "    \"Torres\": r\"D:\\Data\\mab\\ACdataset\\Torres\\torres.csv\",\n",
    "    \"Aggro\": r\"D:\\Data\\mab\\ACdataset\\Aggro\\pre_lesion\\Aggro_Pre.csv\",\n",
    "    \"Auroma\": r\"D:\\Data\\mab\\ACdataset\\Auroma\\Auroma.csv\",\n",
    "    \"Grump\": r\"D:\\Data\\mab\\ASdataset\\Grump\\GrumpExp1Unstructured\\GrumpExp1Unstructured.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_animals(unstructured_paths_unsubsetted):\n",
    "    data = {}\n",
    "    for animal, path in unstructured_paths_unsubsetted.items():\n",
    "        data[animal] = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Function: Compute performance index\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def calculate_performance_index(df):\n",
    "    df = df.copy()\n",
    "    df[\"maxrp\"] = df[[\"rewprobfull1\", \"rewprobfull2\"]].max(axis=1)\n",
    "    df[\"hard_regret\"] = (df[\"maxrp\"] - df[\"rw\"]).apply(lambda x: 0 if x == 0 else 1)\n",
    "    return 1 - df[\"hard_regret\"]\n",
    "\n",
    "\n",
    "def plot_combined_performance(\n",
    "    animal_dict,\n",
    "    cmap=\"viridis\",\n",
    "    svg_name=None,\n",
    "    remove_diagonal=False,\n",
    "    title=None,\n",
    "    fontsize=18,\n",
    "):\n",
    "    all_dfs = []\n",
    "    # Compute PI for each animal\n",
    "    for animal, df in animal_dict.items():\n",
    "        df = df.copy()\n",
    "        df[\"PI\"] = calculate_performance_index(df)\n",
    "        # Ensure maxp ≥ minp\n",
    "        df[\"pair\"] = list(zip(df[\"rewprobfull1\"], df[\"rewprobfull2\"]))\n",
    "        df[\"pair\"] = df[\"pair\"].apply(lambda x: tuple(sorted(x, reverse=True)))\n",
    "        all_dfs.append(df[[\"pair\", \"PI\"]])\n",
    "\n",
    "    combined = pd.concat(all_dfs)\n",
    "    # Average PI\n",
    "    avg_df = combined.groupby(\"pair\")[\"PI\"].mean().reset_index()\n",
    "    avg_df[\"maxp\"] = avg_df[\"pair\"].apply(lambda x: int(x[0]))\n",
    "    avg_df[\"minp\"] = avg_df[\"pair\"].apply(lambda x: int(x[1]))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # FULL probability grid, including 50\n",
    "    # -----------------------------------------\n",
    "\n",
    "    full_probs = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    # We want minp on Y and maxp on X\n",
    "    mat = avg_df.pivot_table(index=\"minp\", columns=\"maxp\", values=\"PI\").reindex(\n",
    "        index=full_probs, columns=full_probs\n",
    "    )\n",
    "    # Sort so 10 (0.1) is near origin (bottom-left)\n",
    "    mat = mat.sort_index(ascending=True)\n",
    "    mat = mat[sorted(mat.columns)]\n",
    "    # -----------------------------------------\n",
    "    # BLANK OUT diagonal (same-probability pairs)\n",
    "    # -----------------------------------------\n",
    "\n",
    "    for p in full_probs:\n",
    "        mat.loc[p, p] = None  # removes annotation + color from heatmap\n",
    "    # --- PLOT ---\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(\n",
    "        mat,\n",
    "        annot=False,\n",
    "        fmt=\".2f\",\n",
    "        cmap=cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        square=True,\n",
    "        # annot_kws={\"size\": fontsize - 2},\n",
    "        mask=mat.isna(),  # hide diagonal cleanly\n",
    "    )\n",
    "\n",
    "    # Tick labels as probabilities 0.1–0.9\n",
    "\n",
    "    prob_labels = [p / 100 for p in full_probs]\n",
    "    plt.xticks(\n",
    "        ticks=range(len(full_probs)), labels=prob_labels, fontsize=fontsize, rotation=0\n",
    "    )\n",
    "\n",
    "    plt.yticks(ticks=range(len(full_probs)), labels=prob_labels, fontsize=fontsize)\n",
    "\n",
    "    # Lower prob (0.1) closest to origin → Y-axis invert\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Higher reward probability\", fontsize=fontsize + 2)\n",
    "    plt.ylabel(\"Lower reward probability\", fontsize=fontsize + 2)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=fontsize + 4, pad=15)\n",
    "    if svg_name is not None:\n",
    "        plt.savefig(svg_name, format=\"svg\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "unstructured_dfs = load_animals(unstructured_paths_unsubsetted)\n",
    "\n",
    "plot_combined_performance(\n",
    "    unstructured_dfs,\n",
    "    cmap=\"Blues\",  # use whatever cmap you like\n",
    "    remove_diagonal=True,\n",
    "    svg_name=\"unstructured_PI_no_diag.svg\",\n",
    "    # title=\"Unstructured Environment — Performance Index\",\n",
    "    fontsize=20,  # perfect size for posters\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
