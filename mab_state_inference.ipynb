{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2dc4b4",
   "metadata": {},
   "source": [
    "### Test fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64756b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mab_subjects\n",
    "from banditpy.models.policy import StateInference2Arm\n",
    "from banditpy.models import DecisionModel\n",
    "from banditpy.models.optim import OptunaOptimizer\n",
    "\n",
    "exps = mab_subjects.mostly_unstruc.allsess + mab_subjects.mostly_struc.allsess\n",
    "\n",
    "for e, exp in enumerate(exps[:1]):\n",
    "\n",
    "    task = exp.b2a.filter_by_trials(100, 100)\n",
    "    task.auto_block_window_ids()\n",
    "    policy = StateInference2Arm()\n",
    "    model = DecisionModel(task=task, policy=policy, reset_mode=\"window\")\n",
    "    model.fit(optimizer=OptunaOptimizer(n_trials=30, timeout=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_sim = model.simulate_posterior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "\n",
    "fig = plotting.Fig(1, 2)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "ax.plot(task.get_optimal_choice_probability())\n",
    "ax.plot(task_sim.get_optimal_choice_probability())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9d24f",
   "metadata": {},
   "source": [
    "### Plotting parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mab_subjects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuropy import plotting\n",
    "from mab_colors import Palette2Arm\n",
    "from statplotannot.plots import SeabornPlotter\n",
    "from statplotannot.plots.plot_utils import xtick_format\n",
    "\n",
    "data_df = mab_subjects.GroupData().fit_si.latest\n",
    "\n",
    "fig = plotting.Fig(4, 7, fontsize=10)\n",
    "palette = Palette2Arm().as_dict()\n",
    "strip_kw = dict(size=5, linewidth=0.3, alpha=0.7, palette=palette)\n",
    "bar_kw = dict(alpha=0.5, palette=palette)\n",
    "\n",
    "for i, block in enumerate([\"block_all\", \"block1\", \"block2_plus\"]):\n",
    "    scope_df = data_df[data_df[\"fit_scope\"] == block]\n",
    "\n",
    "    alpha_df = scope_df[scope_df[\"param_names\"].isin([\"c\", \"y\", \"b0\"])]\n",
    "    beta_df = scope_df[scope_df[\"param_names\"].isin([\"beta\"])]\n",
    "\n",
    "    nll_df = scope_df.loc[scope_df[\"param_names\"] == \"nll\"].copy()\n",
    "    trial_vals = scope_df.loc[\n",
    "        scope_df[\"param_names\"] == \"n_trials\", \"param_values\"\n",
    "    ].to_numpy()\n",
    "\n",
    "    nll_df.loc[:, \"param_values\"] = nll_df[\"param_values\"].to_numpy() / trial_vals\n",
    "\n",
    "    plot_kw = dict(\n",
    "        x=\"param_names\", y=\"param_values\", hue=\"grp\", hue_order=[\"unstruc\", \"struc\"]\n",
    "    )\n",
    "\n",
    "    fig_pos = [fig.gs[i, 0:2], fig.gs[i, 2], fig.gs[i, 3]]\n",
    "    for p, param_df in enumerate([alpha_df, beta_df, nll_df]):\n",
    "\n",
    "        ax = fig.subplot(fig_pos[p])\n",
    "        SeabornPlotter(data=param_df, ax=ax, **plot_kw).stripplot(**strip_kw).barplot(\n",
    "            **bar_kw\n",
    "        ).bootstrap_test()\n",
    "\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.legend_.remove()\n",
    "\n",
    "        if p == 0:\n",
    "            ax.set_title(f\"{block} - Learning rates\")\n",
    "        if p == 1:\n",
    "            xtick_format(ax, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c5a74",
   "metadata": {},
   "source": [
    "### Compare actual vs simulated performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.models import DecisionModel\n",
    "from banditpy.models.policy import StateInference2Arm\n",
    "import mab_subjects\n",
    "from banditpy.core import mab\n",
    "\n",
    "exps = mab_subjects.mostly_unstruc.allsess + mab_subjects.mostly_struc.allsess\n",
    "est_params_df = mab_subjects.GroupData().fit_si.latest\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for exp in exps:\n",
    "    name = exp.sub_name\n",
    "    print(name)\n",
    "\n",
    "    task = exp.b2a.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    task.auto_block_window_ids()\n",
    "\n",
    "    task_specs = [\n",
    "        (\"block_all\", task, task.get_block_start_mask(start=1)),\n",
    "        (\n",
    "            \"block1\",\n",
    "            task_block1 := task.filter_by_block_id(start=1, stop=1),\n",
    "            task_block1.get_block_start_mask(start=1, stop=1),\n",
    "        ),\n",
    "        (\n",
    "            \"block2_plus\",\n",
    "            task_block2 := task.filter_by_block_id(start=2),\n",
    "            task_block2.get_block_start_mask(start=2, stop=2),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    sims_perf = {}\n",
    "    for scope, scoped_task, reset_mask in task_specs:\n",
    "        scope_rows = (est_params_df[\"name\"] == name) & (\n",
    "            est_params_df[\"fit_scope\"] == scope\n",
    "        )\n",
    "        params = dict(\n",
    "            zip(\n",
    "                est_params_df.loc[scope_rows, \"param_names\"],\n",
    "                est_params_df.loc[scope_rows, \"param_values\"],\n",
    "            )\n",
    "        )\n",
    "        policy = StateInference2Arm()\n",
    "        model = DecisionModel(scoped_task, policy=policy, reset_mode=reset_mask)\n",
    "        model.params = {k: params[k] for k in policy.param_names()}\n",
    "        sims_perf[scope] = (\n",
    "            model.simulate_posterior_predictive().get_optimal_choice_probability()\n",
    "        )\n",
    "\n",
    "    sub_df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"trial_id\": np.arange(100) + 1,\n",
    "            \"perf_all\": task.get_optimal_choice_probability(),\n",
    "            \"sim_perf_all\": sims_perf[\"block_all\"],\n",
    "            \"perf_block1\": task_block1.get_optimal_choice_probability(),\n",
    "            \"sim_perf_block1\": sims_perf[\"block1\"],\n",
    "            \"perf_block2plus\": task_block2.get_optimal_choice_probability(),\n",
    "            \"sim_perf_block2plus\": sims_perf[\"block2_plus\"],\n",
    "            \"grp\": exp.group_tag,\n",
    "        }\n",
    "    )\n",
    "    perf_df.append(sub_df)\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(perf_df, \"fit_si_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "from mab_colors import Palette2Arm\n",
    "import numpy as np\n",
    "\n",
    "fig = plotting.Fig(4, 2, size=(8.5, 11), fontsize=10)\n",
    "\n",
    "df = mab_subjects.GroupData().fit_si_sim.latest\n",
    "\n",
    "hue_order = [\"unstruc\", \"struc\"]\n",
    "plot_kw = dict(\n",
    "    data=df,\n",
    "    x=\"trial_id\",\n",
    "    hue=\"grp\",\n",
    "    hue_order=hue_order,\n",
    "    palette=Palette2Arm().as_dict(),\n",
    "    linewidth=1,\n",
    "    errorbar=\"se\",\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    ")\n",
    "\n",
    "for i, block in enumerate([\"all\", \"block1\", \"block2plus\"]):\n",
    "    ax = fig.subplot(fig.gs[i])\n",
    "    sns.lineplot(y=f\"perf_{block}\", ax=ax, linestyle=\"solid\", **plot_kw)\n",
    "    sns.lineplot(y=f\"sim_perf_{block}\", ax=ax, linestyle=\"dashed\", **plot_kw)\n",
    "\n",
    "    ax.set_title(f\"{block}: actual vs simulated\")\n",
    "    ax.set_ylabel(\"P (Optimal choice)\")\n",
    "    ax.set_ylim(0.45, 0.9)\n",
    "    ax.set_xticks([1, 25, 50, 75, 100])\n",
    "    # ax.get_legend().remove()\n",
    "    # ax.legend(['a','b','c','d'])\n",
    "\n",
    "    ax.legend([\"unstruc - actual\", \"struc - actual\", \"unstruc - sim\", \"struc - sim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a47d96",
   "metadata": {},
   "source": [
    "### Comparing switching behavior between actual and simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81124956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.models import DecisionModel\n",
    "from banditpy.models.policy import StateInference2Arm\n",
    "import mab_subjects\n",
    "from banditpy.core import mab\n",
    "from banditpy.analyses import SwitchProb2Arm\n",
    "\n",
    "exps = mab_subjects.mostly_unstruc.allsess + mab_subjects.mostly_struc.allsess\n",
    "est_params_df = mab_subjects.GroupData().fit_si.latest\n",
    "\n",
    "swp_df = []\n",
    "\n",
    "for exp in exps:\n",
    "    name = exp.sub_name\n",
    "    print(name)\n",
    "\n",
    "    task = exp.b2a.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    task.auto_block_window_ids()\n",
    "\n",
    "    task_specs = [\n",
    "        (\"block_all\", task, task.get_block_start_mask(start=1)),\n",
    "        (\n",
    "            \"block1\",\n",
    "            task_block1 := task.filter_by_block_id(start=1, stop=1),\n",
    "            task_block1.get_block_start_mask(start=1, stop=1),\n",
    "        ),\n",
    "        (\n",
    "            \"block2_plus\",\n",
    "            task_block2 := task.filter_by_block_id(start=2),\n",
    "            task_block2.get_block_start_mask(start=2, stop=2),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    swp = {}\n",
    "    for scope, scoped_task, reset_mask in task_specs:\n",
    "        scope_rows = (est_params_df[\"name\"] == name) & (\n",
    "            est_params_df[\"fit_scope\"] == scope\n",
    "        )\n",
    "        params = dict(\n",
    "            zip(\n",
    "                est_params_df.loc[scope_rows, \"param_names\"],\n",
    "                est_params_df.loc[scope_rows, \"param_values\"],\n",
    "            )\n",
    "        )\n",
    "        policy = StateInference2Arm()\n",
    "        model = DecisionModel(scoped_task, policy=policy, reset_mode=reset_mask)\n",
    "        model.params = {k: params[k] for k in policy.param_names()}\n",
    "        task_sim = model.simulate_posterior_predictive()\n",
    "\n",
    "        swp[scope] = SwitchProb2Arm(task_sim).by_trial()\n",
    "\n",
    "    sub_df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"trial_id\": np.arange(99) + 1,\n",
    "            \"switch_prob_all\": SwitchProb2Arm(task).by_trial(),\n",
    "            \"sim_switch_prob_all\": swp[\"block_all\"],\n",
    "            \"switch_prob_block1\": SwitchProb2Arm(task_block1).by_trial(),\n",
    "            \"sim_switch_prob_block1\": swp[\"block1\"],\n",
    "            \"switch_prob_block2plus\": SwitchProb2Arm(task_block2).by_trial(),\n",
    "            \"sim_switch_prob_block2plus\": swp[\"block2_plus\"],\n",
    "            \"grp\": exp.group_tag,\n",
    "        }\n",
    "    )\n",
    "    swp_df.append(sub_df)\n",
    "\n",
    "swp_df = pd.concat(swp_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(swp_df, \"switchprob_si\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "from statplotannot.plots import SeabornPlotter\n",
    "import mab_subjects\n",
    "from mab_colors import Palette2Arm\n",
    "\n",
    "\n",
    "df = mab_subjects.GroupData().switchprob_si.latest\n",
    "\n",
    "fig = plotting.Fig(4, 2, fontsize=10)\n",
    "\n",
    "for i, block in enumerate([\"all\", \"block1\", \"block2plus\"]):\n",
    "\n",
    "    ax = fig.subplot(fig.gs[i,0])\n",
    "    SeabornPlotter(\n",
    "        data=df,\n",
    "        x=\"trial_id\",\n",
    "        y=f\"switch_prob_{block}\",\n",
    "        hue=\"grp\",\n",
    "        hue_order=[\"unstruc\", \"struc\"],\n",
    "        palette=Palette2Arm().as_dict(),\n",
    "        err_kws=dict(edgecolor=\"none\"),\n",
    "        ax=ax,\n",
    "    ).lineplot(linestyle=\"solid\",palette=Palette2Arm().as_dict())\n",
    "\n",
    "    ax = fig.subplot(fig.gs[i,1])\n",
    "    SeabornPlotter(\n",
    "        data=df,\n",
    "        x=\"trial_id\",\n",
    "        y=f\"sim_switch_prob_{block}\",\n",
    "        hue=\"grp\",\n",
    "        hue_order=[\"unstruc\", \"struc\"],\n",
    "        palette=Palette2Arm().as_dict(),\n",
    "        err_kws=dict(edgecolor=\"none\"),\n",
    "        ax=ax,\n",
    "    ).lineplot(linestyle=\"solid\",palette=Palette2Arm().as_dict())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
