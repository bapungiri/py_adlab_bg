{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b6f430",
   "metadata": {},
   "source": [
    "### 2 $\\alpha$ model\n",
    "- Estimate learning parameter for chosen and unchosen arms/choices. If the animals are learning, then one should expect that the chosen and unchosen arm will have postive and negative $\\alpha$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12633eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.analyses import QlearningEstimator\n",
    "import mab_subjects\n",
    "\n",
    "exps = mab_subjects.struc.allsess + mab_subjects.unstruc.allsess\n",
    "\n",
    "params_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    mab = exp.mab.keep_by_trials(min_trials=100, clip_max=100)\n",
    "    print(exp.sub_name)\n",
    "    qlearn = QlearningEstimator(mab)\n",
    "    qlearn.fit(\n",
    "        x0=None,\n",
    "        bounds=np.array([(-1, 1), (-1, 1), (0.005, 20)]),\n",
    "        method=\"diff_evolution\",\n",
    "        n_opts=5,\n",
    "        n_cpu=4,\n",
    "    )\n",
    "\n",
    "    qlearn.print_params()\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": exp.sub_name,\n",
    "            \"param\": [\"alpha_chosen\", \"alpha_unchosen\", \"beta\"],\n",
    "            \"param_values\": np.array([qlearn.alpha_c, qlearn.alpha_u, qlearn.beta]),\n",
    "            \"grp\": \"struc\" if mab.is_structured else \"unstruc\",\n",
    "        }\n",
    "    )\n",
    "    params_df.append(df)\n",
    "\n",
    "params_df = pd.concat(params_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(params_df, \"qlearning_2alpha_params_anirudh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ab3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "params_df = mab_subjects.GroupData().qlearning_2alpha_params_anirudh\n",
    "\n",
    "fig = plotting.Fig(1, 2, size=(4, 3), num=1)\n",
    "ax1 = fig.subplot(fig.gs[0])\n",
    "ax2 = fig.subplot(fig.gs[1])\n",
    "\n",
    "plot_kw = dict(x=\"param\", y=\"param_values\", hue=\"grp\")\n",
    "bar_kw = dict(\n",
    "    errorbar=\"se\",\n",
    "    palette=\"dark:black\",\n",
    "    linestyle=\"none\",\n",
    "    alpha=0.5,\n",
    "    dodge=0.4,\n",
    "    zorder=1,\n",
    "    marker=\".\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=0,\n",
    "    err_kws={\"linewidth\": 1},\n",
    ")\n",
    "strip_kw = dict(palette=\"husl\", alpha=0.5, dodge=True, zorder=2)\n",
    "\n",
    "\n",
    "alpha_df = params_df[params_df[\"param\"] != \"beta\"]\n",
    "sns.pointplot(alpha_df, ax=ax1, **plot_kw, **bar_kw)\n",
    "sns.stripplot(alpha_df, ax=ax1, **plot_kw, **strip_kw)\n",
    "\n",
    "beta_df = params_df[params_df[\"param\"] == \"beta\"]\n",
    "sns.pointplot(beta_df, ax=ax2, **plot_kw, **bar_kw)\n",
    "sns.stripplot(beta_df, ax=ax2, **plot_kw, **strip_kw)\n",
    "\n",
    "ax1.set_ylabel(\"Estimated alpha values\")\n",
    "ax2.set_ylabel(\"Estimated beta values\")\n",
    "fig.fig.suptitle(\"Q-learning in two-armed bandit task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bb45e",
   "metadata": {},
   "source": [
    "### 2 $\\alpha$ model + Perserverance + Scaler \n",
    "- When we estimated alpha parameters for chosen and unchosen choices, we found that unstructured env had higher alpha values for chosen arms compared to structured env. So we asked if 'persevrance' for arms/choices is making alpha_chosen higher for unstructured environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627d09b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BewilderbeastExp1Structured\n",
      "alpha_c: 0.0, alpha_u: 0.0,alpha_h: 0.0, scaler: 0.0, beta: 0.0\n",
      "qlearning_2alpha_persev saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.analyses import QlearningEstimator\n",
    "import mab_subjects\n",
    "\n",
    "exps = mab_subjects.struc.allsess + mab_subjects.unstruc.allsess\n",
    "\n",
    "params_df = []\n",
    "\n",
    "for i, exp in enumerate(exps[:1]):\n",
    "    mab = exp.mab.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    print(exp.sub_name)\n",
    "    qlearn = QlearningEstimator(mab, model=\"persev\", n_cpu=4)\n",
    "    qlearn.fit(\n",
    "        bounds=np.array([(-1, 1), (-1, 1), (0, 1), (1, 10), (0.005, 20)]), n_optimize=5\n",
    "    )\n",
    "\n",
    "    qlearn.print_params()\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": exp.sub_name,\n",
    "            \"param\": [\"alpha_chosen\", \"alpha_unchosen\", \"persev\", \"scaler\", \"beta\"],\n",
    "            \"param_values\": qlearn.estimated_params,\n",
    "            \"grp\": \"struc\" if mab.is_structured else \"unstruc\",\n",
    "        }\n",
    "    )\n",
    "    params_df.append(df)\n",
    "\n",
    "params_df = pd.concat(params_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(params_df, \"qlearning_2alpha_persev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32254c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# choices = np.array([1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1])\n",
    "choices = np.array([1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2])\n",
    "alpha_h = 0.2\n",
    "H = 0\n",
    "h_values = []\n",
    "for choice in choices:\n",
    "    H += alpha_h * (choice - H)\n",
    "    h_values.append(H.copy())\n",
    "\n",
    "\n",
    "plt.plot(h_values)\n",
    "plt.plot(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class HabitualController:\n",
    "    def __init__(self, num_actions=2, alpha_H=0.1):\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha_H = alpha_H\n",
    "        self.H = np.zeros(num_actions)  # H0 initialized to zero\n",
    "\n",
    "    def softmax(self, x, tau=0.1):\n",
    "        \"\"\"Softmax action selection with temperature tau (lower tau -> greedier)\"\"\"\n",
    "        exp_x = np.exp(x / tau)\n",
    "        return exp_x / np.sum(exp_x)\n",
    "\n",
    "    def select_action(self):\n",
    "        \"\"\"Select action based on current habit strengths using softmax\"\"\"\n",
    "        probs = self.softmax(self.H)\n",
    "        action = np.random.choice(self.num_actions, p=probs)\n",
    "        return action, probs\n",
    "\n",
    "    def update(self, action):\n",
    "        \"\"\"Update habit strengths based on selected action\"\"\"\n",
    "        a_t = np.zeros(self.num_actions)\n",
    "        a_t[action] = 1\n",
    "        self.H += self.alpha_H * (a_t - self.H)\n",
    "\n",
    "\n",
    "# Example usage (simulating 100 trials)\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    controller = HabitualController(num_actions=2, alpha_H=0.1)\n",
    "\n",
    "    for trial in range(100):\n",
    "        action, probs = controller.select_action()\n",
    "        print(action)\n",
    "        controller.update(action)\n",
    "\n",
    "        print(\n",
    "            f\"Trial {trial+1}: Action={action}, Action Probs={probs}, H={controller.H}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffce100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha_H = 0.2\n",
      "Estimated alpha_H = 0.11682048621725105\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "class HabitualControllerMLE:\n",
    "    def __init__(self, num_actions=2, tau=0.1):\n",
    "        self.num_actions = num_actions\n",
    "        self.tau = tau  # softmax temperature\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x / self.tau)\n",
    "        return exp_x / np.sum(exp_x)\n",
    "\n",
    "    def compute_neg_log_likelihood(self, alpha_H, actions):\n",
    "        H = np.zeros(self.num_actions)\n",
    "        neg_log_likelihood = 0.0\n",
    "\n",
    "        for action in actions:\n",
    "            probs = self.softmax(H)\n",
    "            prob_a = probs[action]\n",
    "            # Avoid log(0)\n",
    "            prob_a = np.clip(prob_a, 1e-10, 1.0)\n",
    "            neg_log_likelihood -= np.log(prob_a)\n",
    "\n",
    "            # Update H\n",
    "            a_t = np.zeros(self.num_actions)\n",
    "            a_t[action] = 1\n",
    "            H += alpha_H * (a_t - H)\n",
    "\n",
    "        return neg_log_likelihood\n",
    "\n",
    "    def fit(self, actions, bounds=(0.001, 1.0)):\n",
    "        \"\"\"Estimate alpha_H via Maximum Likelihood given action sequence\"\"\"\n",
    "        result = minimize(\n",
    "            fun=lambda alpha: self.compute_neg_log_likelihood(alpha[0], actions),\n",
    "            x0=[0.1],  # initial guess\n",
    "            bounds=[bounds],\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        estimated_alpha = result.x[0]\n",
    "        return estimated_alpha, result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Simulate some actions using true alpha_H=0.2\n",
    "    true_alpha_H = 0.2\n",
    "    num_trials = 100\n",
    "    controller = HabitualControllerMLE()\n",
    "    H = np.zeros(2)\n",
    "    actions = []\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        probs = controller.softmax(H)\n",
    "        action = np.random.choice(2, p=probs)\n",
    "        actions.append(action)\n",
    "\n",
    "        a_t = np.zeros(2)\n",
    "        a_t[action] = 1\n",
    "        H += true_alpha_H * (a_t - H)\n",
    "\n",
    "    # Now fit model to recover alpha_H from actions\n",
    "    model = HabitualControllerMLE()\n",
    "    est_alpha, result = model.fit(actions)\n",
    "\n",
    "    print(f\"True alpha_H = {true_alpha_H}\")\n",
    "    print(f\"Estimated alpha_H = {est_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31ab1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated alpha_H = 0.0172\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "class HabitualControllerMLE:\n",
    "    def __init__(self, num_actions=2, tau=0.1):\n",
    "        self.num_actions = num_actions\n",
    "        self.tau = tau\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x / self.tau)\n",
    "        return exp_x / np.sum(exp_x)\n",
    "\n",
    "    def compute_neg_log_likelihood(self, alpha_H, actions):\n",
    "        H = np.zeros(self.num_actions)\n",
    "        neg_log_likelihood = 0.0\n",
    "\n",
    "        for action in actions:\n",
    "            probs = self.softmax(H)\n",
    "            prob_a = probs[action]\n",
    "            prob_a = np.clip(prob_a, 1e-10, 1.0)\n",
    "            neg_log_likelihood -= np.log(prob_a)\n",
    "\n",
    "            a_t = np.zeros(self.num_actions)\n",
    "            a_t[action] = 1\n",
    "            H += alpha_H * (a_t - H)\n",
    "\n",
    "        return neg_log_likelihood\n",
    "\n",
    "    def fit(self, actions, bounds=(0.001, 1.0)):\n",
    "        result = minimize(\n",
    "            fun=lambda alpha: self.compute_neg_log_likelihood(alpha[0], actions),\n",
    "            x0=[0.1],\n",
    "            bounds=[bounds],\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        estimated_alpha = result.x[0]\n",
    "        return estimated_alpha, result\n",
    "\n",
    "\n",
    "# Your action sequence (1 and 2 -> convert to 0 and 1)\n",
    "actions = np.array([1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2]) - 1\n",
    "\n",
    "model = HabitualControllerMLE()\n",
    "est_alpha, result = model.fit(actions)\n",
    "\n",
    "print(f\"Estimated alpha_H = {est_alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from statannotations.stats.StatTest import StatTest\n",
    "from statplot_utils import stat_kw\n",
    "\n",
    "params_df = mab_subjects.GroupData().qlearning_2alpha_persev_anirudh\n",
    "\n",
    "fig = plotting.Fig(1, 3, size=(6, 4), num=1)\n",
    "ax1 = fig.subplot(fig.gs[0])\n",
    "ax2 = fig.subplot(fig.gs[1])\n",
    "\n",
    "plot_kw = dict(x=\"param\", y=\"param_values\", hue=\"grp\", hue_order=[\"unstruc\", \"struc\"])\n",
    "bar_kw = dict(\n",
    "    errorbar=\"se\",\n",
    "    palette=\"dark:black\",\n",
    "    linestyle=\"none\",\n",
    "    alpha=0.5,\n",
    "    dodge=0.4,\n",
    "    zorder=1,\n",
    "    marker=\".\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=0,\n",
    "    err_kws={\"linewidth\": 1},\n",
    ")\n",
    "strip_kw = dict(palette=\"husl\", alpha=0.5, dodge=True, zorder=2)\n",
    "\n",
    "indx_bool = params_df[\"param\"].isin([\"scaler\", \"beta\"])\n",
    "\n",
    "alpha_df = params_df[~indx_bool]\n",
    "sns.pointplot(alpha_df, ax=ax1, **plot_kw, **bar_kw)\n",
    "sns.stripplot(alpha_df, ax=ax1, **plot_kw, **strip_kw)\n",
    "\n",
    "orders = [\"alpha_chosen\", \"alpha_unchosen\", \"persev\"]\n",
    "pairs = [((_, \"unstruc\"), (_, \"struc\")) for _ in orders]\n",
    "annotator = Annotator(pairs=pairs, data=alpha_df, ax=ax1, **plot_kw, order=orders)\n",
    "annotator.configure(test=\"t-test_ind\", **stat_kw, color=\"k\", verbose=True)\n",
    "annotator.apply_and_annotate()\n",
    "annotator.reset_configuration()\n",
    "\n",
    "\n",
    "beta_df = params_df[indx_bool]\n",
    "sns.pointplot(beta_df, ax=ax2, **plot_kw, **bar_kw)\n",
    "sns.stripplot(beta_df, ax=ax2, **plot_kw, **strip_kw)\n",
    "\n",
    "orders = [\"scaler\", \"beta\"]\n",
    "pairs = [((_, \"unstruc\"), (_, \"struc\")) for _ in orders]\n",
    "annotator = Annotator(pairs=pairs, data=beta_df, ax=ax2, **plot_kw, order=orders)\n",
    "annotator.configure(test=\"t-test_ind\", **stat_kw, color=\"k\", verbose=True)\n",
    "annotator.apply_and_annotate()\n",
    "annotator.reset_configuration()\n",
    "\n",
    "\n",
    "ax1.axhline(0, ls=\"--\", color=\"gray\", zorder=0, lw=0.8)\n",
    "ax2.set_xlim(-1, 2)\n",
    "ax2.set_ylim(1, 15)\n",
    "\n",
    "ax1.tick_params(axis=\"x\", rotation=30)\n",
    "ax2.tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax1.legend_.remove()\n",
    "ax2.legend_.remove()\n",
    "ax1.set_ylabel(\"Estimated alpha values\")\n",
    "ax2.set_ylabel(\"Estimated beta values\")\n",
    "fig.fig.suptitle(\"Q-learning in two-armed bandit task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6695a17",
   "metadata": {},
   "source": [
    "### Asses estimated params from 2alpha+presev+scaler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.analyses import QlearningEstimator\n",
    "import mab_subjects\n",
    "from banditpy.core import MultiArmedBandit\n",
    "\n",
    "exps = mab_subjects.struc.first_exposure + mab_subjects.unstruc.first_exposure\n",
    "est_params_df = mab_subjects.GroupData().qlearning_2alpha_persev_anirudh\n",
    "\n",
    "# param_order = [\"alpha_chosen\", \"alpha_unchosen\", \"persev\", \"scaler\", \"beta\"]\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    mab = exp.mab.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    name = exp.sub_name\n",
    "    print(name)\n",
    "\n",
    "    qlearn = QlearningEstimator(mab, bounds=None, model=\"persev\")\n",
    "\n",
    "    df = est_params_df[est_params_df[\"name\"] == name]\n",
    "    params = np.array(\n",
    "        [\n",
    "            df.loc[df[\"param\"] == \"alpha_chosen\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"alpha_unchosen\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"persev\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"scaler\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"beta\", \"param_values\"].to_numpy(),\n",
    "        ]\n",
    "    )\n",
    "    predicted_choices = qlearn.predict_choices(params=params, deterministic=False)\n",
    "    predicted_choices[predicted_choices == 0] = 2\n",
    "    predicted_choices[predicted_choices == 1] = 1\n",
    "\n",
    "    new_mab = MultiArmedBandit(\n",
    "        probs=mab.probs,\n",
    "        choices=predicted_choices,\n",
    "        rewards=mab.rewards,\n",
    "        session_ids=mab.session_ids,\n",
    "        starts=mab.starts,\n",
    "        stops=mab.stops,\n",
    "        datetime=mab.datetime,\n",
    "    )\n",
    "\n",
    "    sub_df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": exp.sub_name,\n",
    "            \"trial_id\": np.arange(100) + 1,\n",
    "            \"perf\": mab.get_performance(),\n",
    "            \"perf_new\": new_mab.get_performance(),\n",
    "            \"grp\": \"struc\" if mab.is_structured else \"unstruc\",\n",
    "        }\n",
    "    )\n",
    "    perf_df.append(sub_df)\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "\n",
    "mab_subjects.GroupData().save(perf_df, \"perf_qlearning_assess_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79518195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "from statannotations.Annotator import Annotator\n",
    "from statplot_utils import stat_kw\n",
    "\n",
    "fig = plotting.Fig(8, 4, size=(8.5, 11), num=2)\n",
    "\n",
    "grpdata = mab_subjects.GroupData()\n",
    "df = grpdata.perf_qlearning_assess_params\n",
    "\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "# ax.axhline(0, color=\"gray\", lw=0.8, zorder=0)\n",
    "hue_order = [\"unstruc\", \"struc\"]\n",
    "plot_kw = dict(data=df, x=\"trial_id\", y=\"perf\", hue=\"grp\", hue_order=hue_order, ax=ax)\n",
    "sns.lineplot(\n",
    "    palette=[\"#f77189\", \"#36ada4\"],\n",
    "    # edgecolor=\"white\",\n",
    "    # facecolor=(0, 0, 0, 0),\n",
    "    # alpha=0.4,\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    "    errorbar=\"se\",\n",
    "    **plot_kw,\n",
    ")\n",
    "plot_kw = dict(\n",
    "    data=df, x=\"trial_id\", y=\"perf_new\", hue=\"grp\", hue_order=hue_order, ax=ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    palette=[\"#f77189\", \"#36ada4\"],\n",
    "    linestyle=\"--\",\n",
    "    # facecolor=(0, 0, 0, 0),\n",
    "    # alpha=0.4,\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    "    errorbar=\"se\",\n",
    "    **plot_kw,\n",
    ")\n",
    "\n",
    "# orders = [\"unstruc\", \"struc\"]\n",
    "# pairs = [((\"unstruc\"), (\"struc\"))]\n",
    "# annotator = Annotator(pairs=pairs, order=orders, **plot_kw)\n",
    "# annotator.configure(test=\"Kruskal\", **stat_kw, color=\"k\", verbose=True)\n",
    "# annotator.apply_and_annotate()\n",
    "# annotator.reset_configuration()\n",
    "# ax.grid(True)\n",
    "ax.set_title(\"Performance\")\n",
    "ax.set_ylabel(\"Performance\")\n",
    "ax.set_ylim(0.45, 1)\n",
    "ax.set_xticks([1, 50, 100])\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc2b41",
   "metadata": {},
   "source": [
    "### Params estimation for \"Structured\" sessions in Unstructured Environment.\n",
    "- Basically select sessions where the probabilities sum up to 1 i.e, correlated sessions withing Unstructured environment. Estimate various params like alpha_chosen, alpha_unchosen etc. on these sessions and compare these with Structured Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.analyses import QlearningEstimator\n",
    "import mab_subjects\n",
    "\n",
    "exps = mab_subjects.unstruc.allsess\n",
    "\n",
    "params_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    mab = exp.mab.keep_by_trials(min_trials=100, clip_max=100)\n",
    "    print(exp.sub_name)\n",
    "    session_prob_sum = mab.probs[mab.is_session_start.astype(bool)].sum(axis=1)\n",
    "    good_sessions = mab.sessions[session_prob_sum == 1]\n",
    "    assert np.all(good_sessions)\n",
    "\n",
    "    mab = mab.keep_sessions_by_id(good_sessions)\n",
    "\n",
    "    qlearn = QlearningEstimator(mab, model=\"persev\")\n",
    "    qlearn.fit(\n",
    "        x0=None,\n",
    "        bounds=np.array([(-1, 1), (-1, 1), (0, 1), (1, 10), (0.005, 20)]),\n",
    "        method=\"diff_evolution\",\n",
    "        n_opts=5,\n",
    "        n_cpu=4,\n",
    "    )\n",
    "\n",
    "    qlearn.print_params()\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": exp.sub_name,\n",
    "            \"param\": [\"alpha_chosen\", \"alpha_unchosen\", \"persev\", \"scaler\", \"beta\"],\n",
    "            \"param_values\": qlearn.estimated_params,\n",
    "            \"grp\": \"struc\" if mab.is_structured else \"unstruc\",\n",
    "        }\n",
    "    )\n",
    "    params_df.append(df)\n",
    "\n",
    "params_df = pd.concat(params_df, ignore_index=True)\n",
    "mab_subjects.GroupData().save(\n",
    "    params_df, \"qlearning_2alpha_persev_correlated_within_unstructured_anirudh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "from statannotations.stats.StatTest import StatTest\n",
    "from statplot_utils import stat_kw\n",
    "\n",
    "df1 = mab_subjects.GroupData().qlearning_2alpha_persev_anirudh\n",
    "df2 = (\n",
    "    mab_subjects.GroupData().qlearning_2alpha_persev_correlated_within_unstructured_anirudh\n",
    ")\n",
    "df2[\"grp\"] = \"struc_in_unstruc\"\n",
    "params_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "fig = plotting.Fig(1, 3, size=(6, 4), num=1)\n",
    "ax1 = fig.subplot(fig.gs[0])\n",
    "ax2 = fig.subplot(fig.gs[1])\n",
    "\n",
    "plot_kw = dict(\n",
    "    x=\"param\",\n",
    "    y=\"param_values\",\n",
    "    hue=\"grp\",\n",
    "    hue_order=[\"unstruc\", \"struc\", \"struc_in_unstruc\"],\n",
    ")\n",
    "bar_kw = dict(\n",
    "    errorbar=\"se\",\n",
    "    palette=\"dark:black\",\n",
    "    linestyle=\"none\",\n",
    "    alpha=0.5,\n",
    "    dodge=0.4,\n",
    "    zorder=1,\n",
    "    marker=\".\",\n",
    "    markersize=10,\n",
    "    markeredgewidth=0,\n",
    "    err_kws={\"linewidth\": 1},\n",
    ")\n",
    "strip_kw = dict(palette=\"husl\", alpha=0.5, dodge=True, zorder=2)\n",
    "\n",
    "indx_bool = params_df[\"param\"].isin([\"scaler\", \"beta\"])\n",
    "\n",
    "alpha_df = params_df[~indx_bool]\n",
    "sns.pointplot(alpha_df, ax=ax1, **plot_kw, **bar_kw)\n",
    "sns.stripplot(alpha_df, ax=ax1, **plot_kw, **strip_kw)\n",
    "\n",
    "# orders = [\"alpha_chosen\", \"alpha_unchosen\", \"persev\"]\n",
    "# pairs = [((_, \"unstruc\"), (_, \"struc\")) for _ in orders]\n",
    "# annotator = Annotator(pairs=pairs, data=alpha_df, ax=ax1, **plot_kw, order=orders)\n",
    "# annotator.configure(test=\"t-test_ind\", **stat_kw, color=\"k\", verbose=True)\n",
    "# annotator.apply_and_annotate()\n",
    "# annotator.reset_configuration()\n",
    "\n",
    "\n",
    "beta_df = params_df[indx_bool]\n",
    "sns.pointplot(beta_df, ax=ax2, **plot_kw, **bar_kw)\n",
    "sns.stripplot(beta_df, ax=ax2, **plot_kw, **strip_kw)\n",
    "\n",
    "# orders = [\"scaler\", \"beta\"]\n",
    "# pairs = [((_, \"unstruc\"), (_, \"struc\")) for _ in orders]\n",
    "# annotator = Annotator(pairs=pairs, data=beta_df, ax=ax2, **plot_kw, order=orders)\n",
    "# annotator.configure(test=\"t-test_ind\", **stat_kw, color=\"k\", verbose=True)\n",
    "# annotator.apply_and_annotate()\n",
    "# annotator.reset_configuration()\n",
    "\n",
    "\n",
    "ax1.axhline(0, ls=\"--\", color=\"gray\", zorder=0, lw=0.8)\n",
    "ax2.set_xlim(-1, 2)\n",
    "ax2.set_ylim(1, 15)\n",
    "\n",
    "ax1.tick_params(axis=\"x\", rotation=30)\n",
    "ax2.tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax1.legend_.remove()\n",
    "ax2.legend_.remove()\n",
    "ax1.set_ylabel(\"Estimated alpha values\")\n",
    "ax2.set_ylabel(\"Estimated beta values\")\n",
    "fig.fig.suptitle(\"Q-learning in two-armed bandit task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6daca0",
   "metadata": {},
   "source": [
    "### Fit Qlerning params from one env to other.\n",
    "- Take average of parameters like alpha_chosen, persev etc. from structured environment and predict actions in unstructured env. Following this calculate performance and compare that to actual performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from banditpy.analyses import QlearningEstimator\n",
    "import mab_subjects\n",
    "from banditpy.core import MultiArmedBandit\n",
    "\n",
    "exps = mab_subjects.struc.first_exposure + mab_subjects.unstruc.first_exposure\n",
    "est_params_df = mab_subjects.GroupData().qlearning_2alpha_persev_anirudh\n",
    "mean_params_df = (\n",
    "    est_params_df.groupby([\"grp\", \"param\"]).mean(numeric_only=True).reset_index()\n",
    ")\n",
    "\n",
    "mean_struc = mean_params_df[mean_params_df[\"grp\"] == \"struc\"]\n",
    "mean_unstruc = mean_params_df[mean_params_df[\"grp\"] == \"unstruc\"]\n",
    "param_order = [\"alpha_chosen\", \"alpha_unchosen\", \"persev\", \"scaler\", \"beta\"]\n",
    "\n",
    "perf_df = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    mab = exp.mab.filter_by_trials(min_trials=100, clip_max=100)\n",
    "    name = exp.sub_name\n",
    "    print(name)\n",
    "\n",
    "    qlearn = QlearningEstimator(mab, bounds=None, model=\"persev\")\n",
    "\n",
    "    if mab.is_structured:\n",
    "        df = mean_unstruc.copy()\n",
    "    else:\n",
    "        df = mean_struc.copy()\n",
    "\n",
    "    params = np.array(\n",
    "        [\n",
    "            df.loc[df[\"param\"] == \"alpha_chosen\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"alpha_unchosen\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"persev\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"scaler\", \"param_values\"].to_numpy(),\n",
    "            df.loc[df[\"param\"] == \"beta\", \"param_values\"].to_numpy(),\n",
    "        ]\n",
    "    )\n",
    "    predicted_choices = qlearn.predict_choices(params=params, deterministic=False)\n",
    "    predicted_choices[predicted_choices == 0] = 2\n",
    "    predicted_choices[predicted_choices == 1] = 1\n",
    "\n",
    "    new_mab = MultiArmedBandit(\n",
    "        probs=mab.probs,\n",
    "        choices=predicted_choices,\n",
    "        rewards=mab.rewards,\n",
    "        session_ids=mab.session_ids,\n",
    "        starts=mab.starts,\n",
    "        stops=mab.stops,\n",
    "        datetime=mab.datetime,\n",
    "    )\n",
    "\n",
    "    sub_df = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": exp.sub_name,\n",
    "            \"trial_id\": np.arange(100) + 1,\n",
    "            \"perf\": mab.get_performance(),\n",
    "            \"perf_new\": new_mab.get_performance(),\n",
    "            \"grp\": \"struc\" if mab.is_structured else \"unstruc\",\n",
    "        }\n",
    "    )\n",
    "    perf_df.append(sub_df)\n",
    "\n",
    "perf_df = pd.concat(perf_df, ignore_index=True)\n",
    "\n",
    "mab_subjects.GroupData().save(perf_df, \"perf_qlearning_switch_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "import mab_subjects\n",
    "import numpy as np\n",
    "from statannotations.Annotator import Annotator\n",
    "from statplot_utils import stat_kw\n",
    "\n",
    "fig = plotting.Fig(8, 4, size=(8.5, 11), num=1)\n",
    "\n",
    "grpdata = mab_subjects.GroupData()\n",
    "df = grpdata.perf_qlearning_switch_params\n",
    "\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "# ax.axhline(0, color=\"gray\", lw=0.8, zorder=0)\n",
    "hue_order = [\"unstruc\", \"struc\"]\n",
    "plot_kw = dict(data=df, x=\"trial_id\", y=\"perf\", hue=\"grp\", hue_order=hue_order, ax=ax)\n",
    "sns.lineplot(\n",
    "    palette=[\"#f77189\", \"#36ada4\"],\n",
    "    # edgecolor=\"white\",\n",
    "    # facecolor=(0, 0, 0, 0),\n",
    "    # alpha=0.4,\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    "    errorbar=\"se\",\n",
    "    **plot_kw,\n",
    ")\n",
    "plot_kw = dict(\n",
    "    data=df, x=\"trial_id\", y=\"perf_new\", hue=\"grp\", hue_order=hue_order, ax=ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    palette=[\"#f77189\", \"#36ada4\"],\n",
    "    linestyle=\"--\",\n",
    "    # facecolor=(0, 0, 0, 0),\n",
    "    # alpha=0.4,\n",
    "    err_kws=dict(edgecolor=\"none\"),\n",
    "    errorbar=\"se\",\n",
    "    **plot_kw,\n",
    ")\n",
    "\n",
    "# orders = [\"unstruc\", \"struc\"]\n",
    "# pairs = [((\"unstruc\"), (\"struc\"))]\n",
    "# annotator = Annotator(pairs=pairs, order=orders, **plot_kw)\n",
    "# annotator.configure(test=\"Kruskal\", **stat_kw, color=\"k\", verbose=True)\n",
    "# annotator.apply_and_annotate()\n",
    "# annotator.reset_configuration()\n",
    "# ax.grid(True)\n",
    "ax.set_title(\"Performance\")\n",
    "ax.set_ylabel(\"Performance\")\n",
    "ax.set_ylim(0.45, 1)\n",
    "ax.set_xticks([1, 50, 100])\n",
    "ax.get_legend().remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
