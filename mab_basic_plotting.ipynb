{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(df):\n",
    "    port1_prob = df.loc[:, \"rewprobfull1\"].to_numpy()\n",
    "    port2_prob = df.loc[:, \"rewprobfull2\"].to_numpy()\n",
    "    port_choice = df.loc[:, \"port\"].to_numpy().astype(int)\n",
    "    prob_choice = df.loc[:, \"rw\"].to_numpy()\n",
    "    is_choice_high = np.max(np.vstack((port1_prob, port2_prob)), axis=0) == prob_choice\n",
    "\n",
    "    is_reward = df.loc[:, \"reward\"].to_numpy()\n",
    "    whr_reward_trial = np.where(is_reward == 1)[0]\n",
    "    rwd_mov_avg = np.convolve(is_reward, np.ones(150) / 150, mode=\"same\")\n",
    "    # rwd_mov_avg_smth = gaussian_filter1d(rwd_mov_avg, 20)\n",
    "    rwd_prob_corr = stats.pearsonr(port1_prob, port2_prob)\n",
    "    dt_time = pd.to_datetime(df[\"eptime\"].to_numpy(), unit=\"s\")\n",
    "    session = df.loc[:, \"session#\"].to_numpy()\n",
    "\n",
    "    choice_arr = np.vstack((port1_prob, port2_prob, prob_choice)).T\n",
    "\n",
    "    return choice_arr, is_choice_high, session, is_reward, rwd_prob_corr, dt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = basepath / \"gronckle.csv\"\n",
    "df = pd.read_csv(f)\n",
    "arr, *_, is_choice_high = get_params(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True], shape=(119127,))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(arr[:, :2], axis=1) == arr[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eptime = df[\"eptime\"].to_numpy()\n",
    "dt_time = pd.to_datetime(eptime, unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2188b03f390>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(dt_time.hour, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 70, 70],\n",
       "       [30, 70, 70],\n",
       "       [30, 70, 70],\n",
       "       ...,\n",
       "       [20, 80, 80],\n",
       "       [20, 80, 80],\n",
       "       [20, 80, 80]], shape=(107711, 3))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_choice = arr[np.where(~is_choice_high)]\n",
    "bad_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, sharey=True)\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    choice_arr, is_choice_high, session_id, *_, rwd_corr, dt_time = get_params(data_df)\n",
    "\n",
    "    good_trials = dt_time > (dt_time[0] + pd.Timedelta(days=10))\n",
    "    choice_arr = choice_arr[good_trials, :]\n",
    "    dt_time = dt_time[good_trials]\n",
    "    is_choice_high = is_choice_high[good_trials]\n",
    "    session_id = session_id[good_trials]\n",
    "\n",
    "    _, n_trials = np.unique(session_id, return_counts=True)\n",
    "\n",
    "    is_choice_high_per_session = np.split(is_choice_high, np.cumsum(n_trials)[:-1])\n",
    "    perf = [np.mean(arr) for arr in is_choice_high_per_session]\n",
    "\n",
    "    perf_slide_view = np.lib.stride_tricks.sliding_window_view(perf, 10)[::5, :]\n",
    "    perf_mean = np.mean(perf_slide_view, axis=1)\n",
    "    perf_std = np.std(perf_slide_view, axis=1)\n",
    "\n",
    "    # whr_reward_trial = np.where(is_reward == 1)[0]\n",
    "    # rwd_mov_avg = np.convolve(is_reward, np.ones(100) / 100, mode=\"same\")\n",
    "    # rwd_mov_avg_smth = gaussian_filter1d(rwd_mov_avg, 20)\n",
    "\n",
    "    axs[i].fill_between(\n",
    "        np.arange(len(perf_mean)), perf_mean - perf_std, perf_mean + perf_std, alpha=0.3\n",
    "    )\n",
    "    axs[i].plot(np.arange(len(perf_mean)), perf_mean, \"k\")\n",
    "    axs[i].set_ylim(0.3)\n",
    "    axs[i].set_title(np.round(rwd_corr[0], 2))\n",
    "    # axs[0, i].plot(rwd_prob1, color=\"g\")\n",
    "    # axs[0].vlines(whr_reward_trial,10,20,alpha=0.1)\n",
    "    # axs[0, i].plot(rwd_prob2, color=\"r\")\n",
    "    # axs[1, i].plot(rwd_mov_avg_smth, \"k\")\n",
    "    # axs[1, i].vlines(np.where(port_choice == 1), 0.1, 0.2, alpha=0.5, color=\"g\")\n",
    "    # axs[1, i].vlines(np.where(port_choice == 2), 0.3, 0.4, alpha=0.5, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.5),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.005780346820809248),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.05319148936170213),\n",
       " np.float64(0.006622516556291391),\n",
       " np.float64(0.0),\n",
       " np.float64(0.001694915254237288),\n",
       " np.float64(0.002527379949452401),\n",
       " np.float64(1.0),\n",
       " np.float64(0.0025526483726866626),\n",
       " np.float64(0.009900990099009901),\n",
       " np.float64(0.0),\n",
       " np.float64(0.001288659793814433),\n",
       " np.float64(0.002890173410404624),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.4175824175824176),\n",
       " np.float64(0.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.00624512099921936),\n",
       " np.float64(0.9220404234841193),\n",
       " np.float64(0.1423841059602649),\n",
       " np.float64(0.019981834695731154),\n",
       " np.float64(0.4152542372881356),\n",
       " np.float64(0.9909470752089137),\n",
       " np.float64(0.045454545454545456),\n",
       " np.float64(0.09203980099502487),\n",
       " np.float64(1.0),\n",
       " np.float64(0.12694063926940638),\n",
       " np.float64(1.0),\n",
       " np.float64(0.00846262341325811),\n",
       " np.float64(0.05459387483355526),\n",
       " np.float64(0.01929260450160772),\n",
       " np.float64(0.2242846094354215),\n",
       " np.float64(0.7662222222222222),\n",
       " np.float64(1.0),\n",
       " np.float64(0.1649805447470817),\n",
       " np.float64(0.05530371713508613),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.6526655896607432),\n",
       " np.float64(1.0),\n",
       " np.float64(0.4),\n",
       " np.float64(0.17073170731707318),\n",
       " np.float64(0.8823529411764706),\n",
       " np.float64(0.7272727272727273),\n",
       " np.float64(0.16666666666666666),\n",
       " np.float64(0.08333333333333333),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.4),\n",
       " np.float64(0.18181818181818182),\n",
       " np.float64(0.125),\n",
       " np.float64(0.18867924528301888),\n",
       " np.float64(0.03146853146853147),\n",
       " np.float64(0.030540328895849646),\n",
       " np.float64(0.9873417721518988),\n",
       " np.float64(0.037183544303797465),\n",
       " np.float64(0.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.011747430249632892),\n",
       " np.float64(0.0028653295128939827),\n",
       " np.float64(0.0037313432835820895),\n",
       " np.float64(0.012488849241748439),\n",
       " np.float64(0.4880952380952381),\n",
       " np.float64(0.00522875816993464),\n",
       " np.float64(1.0),\n",
       " np.float64(0.00234192037470726),\n",
       " np.float64(0.4319029850746269),\n",
       " np.float64(0.9978617248752673),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.020134228187919462),\n",
       " np.float64(0.8639652677279306),\n",
       " np.float64(0.5),\n",
       " np.float64(0.00975609756097561),\n",
       " np.float64(0.13924050632911392),\n",
       " np.float64(0.08662741799831791),\n",
       " np.float64(0.21858288770053477),\n",
       " np.float64(0.014266304347826086),\n",
       " np.float64(0.0),\n",
       " np.float64(0.9230769230769231),\n",
       " np.float64(0.0),\n",
       " np.float64(0.008620689655172414),\n",
       " np.float64(0.9972279972279973),\n",
       " np.float64(0.9811320754716981),\n",
       " np.float64(0.9988425925925926),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8381877022653722),\n",
       " np.float64(0.00990990990990991),\n",
       " np.float64(0.002890173410404624),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.2132295719844358),\n",
       " np.float64(0.009068923821039904),\n",
       " np.float64(0.04456824512534819),\n",
       " np.float64(0.0),\n",
       " np.float64(0.06350082827167311),\n",
       " np.float64(0.007209062821833162),\n",
       " np.float64(0.0013774104683195593),\n",
       " np.float64(0.3380281690140845),\n",
       " np.float64(0.031616982836495035),\n",
       " np.float64(0.6078947368421053),\n",
       " np.float64(0.0008012820512820513),\n",
       " np.float64(0.10067567567567567),\n",
       " np.float64(0.011480362537764351),\n",
       " np.float64(0.017025089605734768),\n",
       " np.float64(0.3684210526315789),\n",
       " np.float64(0.02613240418118467),\n",
       " np.float64(0.0),\n",
       " np.float64(0.28170083523158695),\n",
       " np.float64(0.29545454545454547),\n",
       " np.float64(0.1591375770020534),\n",
       " np.float64(1.0),\n",
       " np.float64(0.37333333333333335),\n",
       " np.float64(0.10959885386819485),\n",
       " np.float64(0.05875299760191847),\n",
       " np.float64(1.0),\n",
       " np.float64(0.18556701030927836),\n",
       " np.float64(0.6666666666666666),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.004640371229698376),\n",
       " np.float64(0.0),\n",
       " np.float64(0.6285714285714286),\n",
       " np.float64(0.010559006211180125),\n",
       " np.float64(0.017703862660944206),\n",
       " np.float64(0.0436817472698908),\n",
       " np.float64(0.01639344262295082),\n",
       " np.float64(1.0),\n",
       " np.float64(0.02197802197802198),\n",
       " np.float64(0.039466370205669815),\n",
       " np.float64(0.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.03236682400539447),\n",
       " np.float64(0.7632600258732212),\n",
       " np.float64(0.016740088105726872),\n",
       " np.float64(0.9959514170040485),\n",
       " np.float64(0.11360718870346598),\n",
       " np.float64(1.0),\n",
       " np.float64(0.008766014834794335),\n",
       " np.float64(0.1111111111111111),\n",
       " np.float64(0.0),\n",
       " np.float64(0.46474358974358976),\n",
       " np.float64(0.08757297748123437),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(0.06420351302241066),\n",
       " np.float64(0.003249390739236393),\n",
       " np.float64(0.09900990099009901),\n",
       " np.float64(0.0071492403932082215),\n",
       " np.float64(0.09144542772861357),\n",
       " np.float64(0.025215252152521524),\n",
       " np.float64(0.0030816640986132513),\n",
       " np.float64(0.002320185614849188),\n",
       " np.float64(1.0),\n",
       " np.float64(0.12612612612612611),\n",
       " np.float64(0.003177124702144559),\n",
       " np.float64(1.0),\n",
       " np.float64(0.0),\n",
       " np.float64(0.834061135371179),\n",
       " np.float64(0.0017921146953405018),\n",
       " np.float64(0.20622568093385213),\n",
       " np.float64(1.0),\n",
       " np.float64(0.004784688995215311),\n",
       " np.float64(0.0),\n",
       " np.float64(0.10306406685236769),\n",
       " np.float64(0.7307692307692307),\n",
       " np.float64(1.0),\n",
       " np.float64(0.6728971962616822),\n",
       " np.float64(0.049019607843137254),\n",
       " np.float64(0.011884550084889643),\n",
       " np.float64(0.9694408322496749),\n",
       " np.float64(0.01676963812886143),\n",
       " np.float64(0.10175975516449885),\n",
       " np.float64(1.0),\n",
       " np.float64(0.38126540673788),\n",
       " np.float64(1.0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(10)\n",
    "split_arr = np.array([3, 3, 3])\n",
    "\n",
    "b = np.hsplit(a, np.cumsum(split_arr))\n",
    "\n",
    "[np.mean(_) for _ in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dstack() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: dstack() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "np.dstack(b, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "         74,  75,  76,  77,  78,  79,  80,  81,  82,  84,  85,  86,  87,\n",
       "         88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "        101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "        153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192,\n",
       "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218,\n",
       "        219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "        232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "        245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
       "        258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271,\n",
       "        272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
       "        285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
       "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "        468, 469, 470, 471, 472, 473, 474]),\n",
       " array([205, 203, 155, 229, 271, 214, 216, 134, 321, 226,  13, 348,  23,\n",
       "        312, 204, 254,  43, 208, 362, 262, 316, 163, 234, 221, 254, 231,\n",
       "         14, 218,  72, 213, 264, 279, 250, 216, 271, 239, 223, 218,  25,\n",
       "        227, 467, 151, 266, 241, 303, 162, 215, 220, 232, 228,  34, 228,\n",
       "        231, 295, 164, 204, 207,  42, 257, 357, 316, 244, 220, 196, 250,\n",
       "        223, 202, 209,  10, 207, 216, 268, 202, 152, 101, 143, 117, 189,\n",
       "        180, 175, 123,  12, 294, 149, 167, 138, 131, 110, 283,  84, 152,\n",
       "        223, 112,  41, 119, 174, 120, 166,  43, 162, 241, 263, 175, 140,\n",
       "         25, 135, 127, 108, 115, 136, 128, 107,  23, 173, 128, 170, 309,\n",
       "         17, 108, 161,  96, 113, 152, 136, 197, 166, 152, 104, 180, 139,\n",
       "        184, 103, 178, 103,  89, 121, 229, 148,  77, 108, 101, 175, 210,\n",
       "        167,  36, 108, 127,  59, 148, 155, 130,  53, 141, 136, 200, 104,\n",
       "        133, 121,  30, 134,  95, 162, 283, 131, 143, 115, 105, 132, 151,\n",
       "         32,  81, 114, 105,  19, 138, 296, 117, 131,  21, 116, 166, 122,\n",
       "        148, 165, 162, 178, 117, 202, 101, 103,  39, 112, 183, 108, 109,\n",
       "        147, 103, 143, 108, 219, 105,  38, 221, 116,  20, 127, 152,  99,\n",
       "        177, 146, 107,  40, 161, 113, 166, 103, 183, 120, 108, 163, 130,\n",
       "        258,   2, 231,  10, 108,  78, 108, 133, 129, 173, 175, 137,  96,\n",
       "        114, 159,  19, 147, 141, 142, 145, 218,   9, 236,  28, 116, 107,\n",
       "        142, 136, 165, 118,  16, 192, 103,  26, 135, 142, 132, 126, 137,\n",
       "        112,  93, 113, 108, 216, 138,  68, 171, 180, 332, 160, 107,  11,\n",
       "        131, 148, 157,   9, 101, 117, 131, 109, 178, 121, 150,  19, 120,\n",
       "        109, 244, 114,  41, 114, 121, 159,  12, 122, 104, 125, 252, 162,\n",
       "        216, 105,  46, 117, 123,  45,  16,  54,  28,  11,  13,   2,  29,\n",
       "         13, 152,  91, 282, 295,  22,  16,   1, 145, 102,  39, 128, 103,\n",
       "        246,  91, 102, 115, 134,  87, 151, 101, 143, 117, 189, 180, 175,\n",
       "        123, 225, 232, 167, 138, 131, 110, 283, 181, 279, 112, 161, 174,\n",
       "        120, 166, 117, 101, 232, 262, 175, 140, 161, 127, 108, 115,  37,\n",
       "        176, 144, 155, 124, 126, 121, 106,  60, 150, 154, 120, 144, 149,\n",
       "        168, 144, 118, 121,  34, 133, 164, 106, 147, 106, 132, 109, 173,\n",
       "        103, 107, 119, 184, 229, 148, 175, 131, 163, 113, 146, 120, 127,\n",
       "        103, 126, 129, 116, 160, 202,   1]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(session, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial#</th>\n",
       "      <th>trialstart</th>\n",
       "      <th>port</th>\n",
       "      <th>reward</th>\n",
       "      <th>trialend</th>\n",
       "      <th>session#</th>\n",
       "      <th>eptime</th>\n",
       "      <th>task</th>\n",
       "      <th>rewprobfull1</th>\n",
       "      <th>rewprobfull2</th>\n",
       "      <th>rw</th>\n",
       "      <th>animal</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4119</td>\n",
       "      <td>1</td>\n",
       "      <td>1696509517</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-10-05 12:38:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5721</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5721</td>\n",
       "      <td>1</td>\n",
       "      <td>1696509519</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-10-05 12:38:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6790</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6873</td>\n",
       "      <td>1</td>\n",
       "      <td>1696509520</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-10-05 12:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10744</td>\n",
       "      <td>1</td>\n",
       "      <td>1696509524</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-10-05 12:38:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12221</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12221</td>\n",
       "      <td>1</td>\n",
       "      <td>1696509526</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-10-05 12:38:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76104</th>\n",
       "      <td>76104</td>\n",
       "      <td>76104</td>\n",
       "      <td>1162679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1163022</td>\n",
       "      <td>167</td>\n",
       "      <td>1702264773</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-12-11 03:19:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76105</th>\n",
       "      <td>76105</td>\n",
       "      <td>76105</td>\n",
       "      <td>1164634</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1164880</td>\n",
       "      <td>167</td>\n",
       "      <td>1702264775</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-12-11 03:19:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76106</th>\n",
       "      <td>76106</td>\n",
       "      <td>76106</td>\n",
       "      <td>1166300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1166421</td>\n",
       "      <td>167</td>\n",
       "      <td>1702264777</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-12-11 03:19:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76107</th>\n",
       "      <td>76107</td>\n",
       "      <td>76107</td>\n",
       "      <td>1167738</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1167836</td>\n",
       "      <td>167</td>\n",
       "      <td>1702264779</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-12-11 03:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76108</th>\n",
       "      <td>76108</td>\n",
       "      <td>76108</td>\n",
       "      <td>1169450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1170068</td>\n",
       "      <td>167</td>\n",
       "      <td>1702264780</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Grump</td>\n",
       "      <td>2023-12-11 03:19:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76109 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  trial#  trialstart  port  reward  trialend  session#  \\\n",
       "0               0       0        4092   2.0       1      4119         1   \n",
       "1               1       1        5721   2.0       0      5721         1   \n",
       "2               2       2        6790   2.0       1      6873         1   \n",
       "3               3       3       10714   2.0       1     10744         1   \n",
       "4               4       4       12221   2.0       1     12221         1   \n",
       "...           ...     ...         ...   ...     ...       ...       ...   \n",
       "76104       76104   76104     1162679   2.0       1   1163022       167   \n",
       "76105       76105   76105     1164634   2.0       1   1164880       167   \n",
       "76106       76106   76106     1166300   2.0       1   1166421       167   \n",
       "76107       76107   76107     1167738   2.0       1   1167836       167   \n",
       "76108       76108   76108     1169450   2.0       1   1170068       167   \n",
       "\n",
       "           eptime  task  rewprobfull1  rewprobfull2  rw animal  \\\n",
       "0      1696509517    13            40            70  70  Grump   \n",
       "1      1696509519    13            40            70  70  Grump   \n",
       "2      1696509520    13            40            70  70  Grump   \n",
       "3      1696509524    13            40            70  70  Grump   \n",
       "4      1696509526    13            40            70  70  Grump   \n",
       "...           ...   ...           ...           ...  ..    ...   \n",
       "76104  1702264773    13            80            90  90  Grump   \n",
       "76105  1702264775    13            80            90  90  Grump   \n",
       "76106  1702264777    13            80            90  90  Grump   \n",
       "76107  1702264779    13            80            90  90  Grump   \n",
       "76108  1702264780    13            80            90  90  Grump   \n",
       "\n",
       "                  datetime  \n",
       "0      2023-10-05 12:38:37  \n",
       "1      2023-10-05 12:38:39  \n",
       "2      2023-10-05 12:38:40  \n",
       "3      2023-10-05 12:38:44  \n",
       "4      2023-10-05 12:38:46  \n",
       "...                    ...  \n",
       "76104  2023-12-11 03:19:33  \n",
       "76105  2023-12-11 03:19:35  \n",
       "76106  2023-12-11 03:19:37  \n",
       "76107  2023-12-11 03:19:39  \n",
       "76108  2023-12-11 03:19:40  \n",
       "\n",
       "[76109 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c114055950>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(rwd_prob1, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients:\n",
      "Beta (Reward history weights): [[-0.03594947 -0.09515691  0.04508803 -0.08742038 -0.02923884]]\n",
      "Beta (Choice history weights): [[ 0.0133873   0.0166049   0.07716208 -0.04840661 -0.0341045 ]]\n",
      "Intercept (Bias term): [0.07619375]\n",
      "Test accuracy: 0.515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simulate some synthetic data for 1000 trials\n",
    "np.random.seed(42)\n",
    "n_trials = 1000\n",
    "n_history = 5  # Number of past trials considered (5 as in the equation)\n",
    "\n",
    "# Simulate reward history (1 for reward, 0 for no reward)\n",
    "reward_left = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Left rewards history\n",
    "reward_right = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Right rewards history\n",
    "\n",
    "# Simulate choice history (1 for chosen, 0 for unchosen)\n",
    "choice_left = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Left choices history\n",
    "choice_right = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Right choices history\n",
    "\n",
    "# Simulate the actual choice (1 for left, 0 for right, as the target variable)\n",
    "# The actual choice depends on some hidden logic; we'll just generate random choices for this example\n",
    "actual_choice = np.random.randint(0, 2, size=n_trials)  # 1 for left, 0 for right\n",
    "\n",
    "# Prepare the feature matrix (X) for the logistic regression model\n",
    "# We combine reward and choice histories for both left and right\n",
    "X = np.hstack(\n",
    "    [\n",
    "        reward_left - reward_right,  # reward history difference\n",
    "        choice_left - choice_right,  # choice history difference\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Standardize the data (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, actual_choice, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Print model coefficients (βr, βc, and βbias)\n",
    "print(\"Model coefficients:\")\n",
    "print(\"Beta (Reward history weights):\", log_reg.coef_[:, :n_history])\n",
    "print(\"Beta (Choice history weights):\", log_reg.coef_[:, n_history:])\n",
    "print(\"Intercept (Bias term):\", log_reg.intercept_)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
