{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import bandit_utils\n",
    "from neuropy import plotting\n",
    "import matplotlib as mpl\n",
    "\n",
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials and reward raw data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, sharey=True)\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "for i, file in enumerate(files[:3]):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "\n",
    "    choice_arr, is_choice_high, session_id, is_reward, rwd_corr, dt_time = (\n",
    "        bandit_utils.from_csv(data_df)\n",
    "    )\n",
    "\n",
    "    good_trials = dt_time > (dt_time[0] + pd.Timedelta(days=10))\n",
    "    choice_arr = choice_arr[good_trials, :]\n",
    "    dt_time = dt_time[good_trials]\n",
    "    is_choice_high = is_choice_high[good_trials]\n",
    "    session_id = session_id[good_trials]\n",
    "    is_reward = is_reward[good_trials].astype(bool)\n",
    "    # is_reward_bool = is_reward.astype(bool)\n",
    "    trials = np.arange(choice_arr.shape[0])\n",
    "    port1_high = choice_arr[:, 0] > choice_arr[:, 1]\n",
    "    session_start_indx = np.unique(session_id, return_index=True)[1]\n",
    "\n",
    "    axs[i].scatter(\n",
    "        trials[is_reward],\n",
    "        choice_arr[is_reward, 3],\n",
    "        color=\"k\",\n",
    "        s=20,\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"w\",\n",
    "    )\n",
    "    axs[i].vlines(session_start_indx, 0, 3, color=\"k\", linestyle=\"--\")\n",
    "    axs[i].scatter(trials[~is_reward], choice_arr[~is_reward, 3], color=\"k\", s=2)\n",
    "    axs[i].fill_between(trials, 0, 3, where=port1_high, color=\"r\", alpha=0.3, ec=None)\n",
    "    axs[i].set_ylim(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"datetime\"][0].day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess learning within sessions and compare early to late\n",
    "- Also based on this, find a systematic way to choose good sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asheshlab\\AppData\\Local\\Temp\\ipykernel_14708\\2392391096.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = mpl.cm.get_cmap(\"Reds\")\n"
     ]
    }
   ],
   "source": [
    "plt.close()\n",
    "fig = plotting.Fig(4, 3, size=(13, 6))\n",
    "cmap = mpl.cm.get_cmap(\"Reds\")\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = bandit_utils.from_csv(basepath / file)\n",
    "    prob_corr = np.abs(\n",
    "        stats.pearsonr(data_df[\"rewprobfull1\"], data_df[\"rewprobfull2\"])[0]\n",
    "    )\n",
    "\n",
    "    task_type = \"unstructured\" if prob_corr < 0.2 else \"structured\"\n",
    "\n",
    "    ntrials_by_session, mean_ntrials, std_ntrials = bandit_utils.get_trial_metrics(\n",
    "        data_df\n",
    "    )\n",
    "\n",
    "    sess_div_perf_arr = bandit_utils.get_performance_2ab(\n",
    "        data_df, min_trials_per_sess=20, roll_window=30, smooth=5\n",
    "    )\n",
    "\n",
    "    sess_div_perf_high_diff_arr = bandit_utils.get_performance_2ab(\n",
    "        data_df, min_trials_per_sess=20, roll_window=30, smooth=5, delta_prob=40\n",
    "    )\n",
    "\n",
    "    port_bias, centers = bandit_utils.get_port_bias_2ab(data_df)\n",
    "    nan_idx = np.isnan(port_bias)\n",
    "\n",
    "    x_cuttoff = mean_ntrials + 2 * std_ntrials\n",
    "    # x_cutoff_bool = trial_x < x_cuttoff\n",
    "\n",
    "    subfig = fig.add_subfigure(fig.gs[i])\n",
    "    subfig.suptitle(f\"{files[i].name[:-4]}, {task_type}\")\n",
    "    sub_axs = subfig.subplots(1, 4, width_ratios=[1, 2, 2, 2])\n",
    "\n",
    "    # ===== trials histogram =======\n",
    "    n_trials_hist, trial_edges = np.histogram(\n",
    "        ntrials_by_session, bins=range(0, 1500, 10)\n",
    "    )\n",
    "    sub_axs[0].stairs(\n",
    "        values=n_trials_hist, edges=trial_edges, fill=True, color=\"#9E9E9E\", alpha=0.7\n",
    "    )\n",
    "    sub_axs[0].axvline(mean_ntrials, color=\"k\", ls=\"--\")\n",
    "    # sub_axs[0].axvline(x_cuttoff, color=\"r\", ls=\"--\")\n",
    "    sub_axs[0].set_xlim(0, x_cuttoff + 10)\n",
    "    sub_axs[0].set_title(\"Trials histogram\")\n",
    "\n",
    "    # ==== All sessions performance ======\n",
    "    # sub_axs[1].plot(trial_x[x_cutoff_bool], prob_correct_per_trial[x_cutoff_bool], \"g\")\n",
    "\n",
    "    perf_arrays = [sess_div_perf_arr, sess_div_perf_high_diff_arr]\n",
    "    perf_titles = [\n",
    "        \"Performance\\n(All sessions)\",\n",
    "        \"Performance\\n\" r\"($\\Delta$P$\\geq$40)\",\n",
    "    ]\n",
    "\n",
    "    for arr_i, arr in enumerate(perf_arrays):\n",
    "        colors = [cmap(_) for _ in np.linspace(0.2, 0.8, arr.shape[0])]\n",
    "        n_trials = arr.shape[1]\n",
    "\n",
    "        for c in range(len(colors)):\n",
    "            sub_axs[arr_i + 1].plot(\n",
    "                np.arange(n_trials), arr[c], color=colors[c], lw=0.7\n",
    "            )\n",
    "        sub_axs[arr_i + 1].set_xlim(0, x_cuttoff)\n",
    "        sub_axs[arr_i + 1].set_ylim(0, 1.2)\n",
    "        sub_axs[arr_i + 1].set_yticks([0, 0.5, 1])\n",
    "        sub_axs[arr_i + 1].set_title(perf_titles[arr_i])\n",
    "\n",
    "    # ====== port bias=========\n",
    "\n",
    "    sub_axs[3].plot(centers[~nan_idx], port_bias[~nan_idx], color=\"g\")\n",
    "    sub_axs[3].spines[\"bottom\"].set_position(\"zero\")\n",
    "    sub_axs[3].spines[\"left\"].set_position(\"zero\")\n",
    "    sub_axs[3].set_ylim(-1, 1)\n",
    "    sub_axs[3].set_xticks([-80, 80])\n",
    "    sub_axs[3].set_yticks([-1, 1])\n",
    "    sub_axs[3].set_title(\"Port bias\")\n",
    "\n",
    "    if i == 0:\n",
    "        sub_axs[0].set_xlabel(\"nTrials\")\n",
    "        sub_axs[0].set_ylabel(\"Counts\")\n",
    "        sub_axs[1].set_xlabel(\"Trials\")\n",
    "        sub_axs[1].set_ylabel(\"Choice P(high)\")\n",
    "        sub_axs[2].set_xlabel(\"Trials\")\n",
    "        sub_axs[2].set_ylabel(\"Choice P(high)\")\n",
    "        sub_axs[3].set_xlabel(\"Reward P(A)-P(B)\")\n",
    "        sub_axs[3].set_ylabel(\"Choice P(A)\")\n",
    "\n",
    "figpath = Path(\n",
    "    \"C:/Users/asheshlab/OneDrive/academia/analyses/adlab/anirudh_data/figures/fig1\"\n",
    ")\n",
    "fig.savefig(figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.plot(centers, bias, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B\n",
       "3   3.0\n",
       "7  14.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4, 6, 3, 1, 2]})\n",
    "df.rolling(window=4, min_periods=2, closed=\"right\").sum()[3::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B\n",
       "0  0.0\n",
       "1  1.0\n",
       "2  2.0\n",
       "3  NaN\n",
       "4  4.0\n",
       "5  6.0\n",
       "6  3.0\n",
       "7  1.0\n",
       "8  2.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High port probability with respect to start of session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3, sharey=True)\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    choice_arr, is_choice_high, session_id, is_reward, rwd_corr, dt_time = get_params(\n",
    "        data_df\n",
    "    )\n",
    "\n",
    "    good_trials = dt_time > (dt_time[0] + pd.Timedelta(days=10))\n",
    "    choice_arr = choice_arr[good_trials, :]\n",
    "    dt_time = dt_time[good_trials]\n",
    "    is_choice_high = is_choice_high[good_trials]\n",
    "    session_id = session_id[good_trials]\n",
    "    is_reward = is_reward[good_trials].astype(bool)\n",
    "    # is_reward_bool = is_reward.astype(bool)\n",
    "    trials = np.arange(choice_arr.shape[0])\n",
    "    port1_high = choice_arr[:, 0] > choice_arr[:, 1]\n",
    "    session_start_indx = np.unique(session_id, return_index=True)[1]\n",
    "\n",
    "    choice_around_session = np.vstack(\n",
    "        [is_choice_high[session_start_indx[:-20] - d] for d in np.arange(-10, 20)]\n",
    "    ).T\n",
    "\n",
    "    prob_high_choice = np.mean(choice_around_session, axis=0)\n",
    "    x = np.arange(-10, 20)\n",
    "\n",
    "    axs[i].plot(x, prob_high_choice)\n",
    "    axs[i].set_ylim(0, 1)\n",
    "    axs[i].set_xticks([-10, 0, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-10, 20).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, sharey=True)\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    choice_arr, is_choice_high, session_id, *_, rwd_corr, dt_time = get_params(data_df)\n",
    "\n",
    "    good_trials = dt_time > (dt_time[0] + pd.Timedelta(days=10))\n",
    "    choice_arr = choice_arr[good_trials, :]\n",
    "    dt_time = dt_time[good_trials]\n",
    "    is_choice_high = is_choice_high[good_trials]\n",
    "    session_id = session_id[good_trials]\n",
    "\n",
    "    session_id_unq, n_trials = np.unique(session_id, return_counts=True)\n",
    "\n",
    "    ax = axs[i]\n",
    "    high_trial_id = session_id_unq[np.where(n_trials > 150)[0][11]]\n",
    "\n",
    "    indx = session_id == high_trial_id\n",
    "\n",
    "    ax.plot(choice_arr[indx, 0], color=\"r\")\n",
    "    ax.plot(choice_arr[indx, 1], color=\"k\")\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(is_choice_high[indx], color=\"gray\")\n",
    "    ax2.set_ylim(-0.2, 1.2)\n",
    "\n",
    "    # alpha_var = np.absolute(session_id)\n",
    "\n",
    "    # is_choice_high_per_session = np.split(is_choice_high, np.cumsum(n_trials)[:-1])\n",
    "    # perf = [np.mean(arr) for arr in is_choice_high_per_session]\n",
    "\n",
    "    # perf_slide_view = np.lib.stride_tricks.sliding_window_view(perf, 10)[::5, :]\n",
    "    # perf_mean = np.mean(perf_slide_view, axis=1)\n",
    "    # perf_std = np.std(perf_slide_view, axis=1)\n",
    "\n",
    "    # whr_reward_trial = np.where(is_reward == 1)[0]\n",
    "    # rwd_mov_avg = np.convolve(is_reward, np.ones(100) / 100, mode=\"same\")\n",
    "    # rwd_mov_avg_smth = gaussian_filter1d(rwd_mov_avg, 20)\n",
    "\n",
    "    # axs[i].fill_between(\n",
    "    #     np.arange(len(perf_mean)), perf_mean - perf_std, perf_mean + perf_std, alpha=0.3\n",
    "    # )\n",
    "    # axs[i].plot(np.arange(len(perf_mean)), perf_mean, \"k\")\n",
    "    # axs[i].set_ylim(0.3)\n",
    "    # axs[i].set_title(np.round(rwd_corr[0], 2))\n",
    "    # axs[0, i].plot(rwd_prob1, color=\"g\")\n",
    "    # axs[0].vlines(whr_reward_trial,10,20,alpha=0.1)\n",
    "    # axs[0, i].plot(rwd_prob2, color=\"r\")\n",
    "    # axs[1, i].plot(rwd_mov_avg_smth, \"k\")\n",
    "    # axs[1, i].vlines(np.where(port_choice == 1), 0.1, 0.2, alpha=0.5, color=\"g\")\n",
    "    # axs[1, i].vlines(np.where(port_choice == 2), 0.3, 0.4, alpha=0.5, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_trial_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "indx = session_id == 61\n",
    "\n",
    "axs[0].plot(choice_arr[indx, 0])\n",
    "axs[0].plot(choice_arr[indx, 1])\n",
    "axs[1].plot(is_choice_high[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(10)\n",
    "split_arr = np.array([3, 3, 3])\n",
    "\n",
    "b = np.hsplit(a, np.cumsum(split_arr))\n",
    "\n",
    "[np.mean(_) for _ in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dstack(b, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(session, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rwd_prob1, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simulate some synthetic data for 1000 trials\n",
    "np.random.seed(42)\n",
    "n_trials = 1000\n",
    "n_history = 5  # Number of past trials considered (5 as in the equation)\n",
    "\n",
    "# Simulate reward history (1 for reward, 0 for no reward)\n",
    "reward_left = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Left rewards history\n",
    "reward_right = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Right rewards history\n",
    "\n",
    "# Simulate choice history (1 for chosen, 0 for unchosen)\n",
    "choice_left = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Left choices history\n",
    "choice_right = np.random.randint(\n",
    "    0, 2, size=(n_trials, n_history)\n",
    ")  # Right choices history\n",
    "\n",
    "# Simulate the actual choice (1 for left, 0 for right, as the target variable)\n",
    "# The actual choice depends on some hidden logic; we'll just generate random choices for this example\n",
    "actual_choice = np.random.randint(0, 2, size=n_trials)  # 1 for left, 0 for right\n",
    "\n",
    "# Prepare the feature matrix (X) for the logistic regression model\n",
    "# We combine reward and choice histories for both left and right\n",
    "X = np.hstack(\n",
    "    [\n",
    "        reward_left - reward_right,  # reward history difference\n",
    "        choice_left - choice_right,  # choice history difference\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Standardize the data (important for logistic regression)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, actual_choice, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Print model coefficients (βr, βc, and βbias)\n",
    "print(\"Model coefficients:\")\n",
    "print(\"Beta (Reward history weights):\", log_reg.coef_[:, :n_history])\n",
    "print(\"Beta (Choice history weights):\", log_reg.coef_[:, n_history:])\n",
    "print(\"Intercept (Bias term):\", log_reg.intercept_)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
