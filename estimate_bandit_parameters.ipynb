{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model\n",
    "- Miller et al. 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))\n",
    "\n",
    "fig = plotting.Fig(6, 3, size=(12, 5), num=1)\n",
    "\n",
    "npast = 10\n",
    "params_pooled = []\n",
    "task_type_bool = []\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    prob_corr = np.abs(\n",
    "        stats.pearsonr(data_df[\"rewprobfull1\"], data_df[\"rewprobfull2\"])[0]\n",
    "    )\n",
    "\n",
    "    task_type = \"unstructured\" if prob_corr < 0.2 else \"structured\"\n",
    "    task_type_bool.append(prob_corr)\n",
    "\n",
    "    choices = data_df[\"port\"].to_numpy()\n",
    "    choices[choices == 2] = -1\n",
    "    outcomes = data_df[\"reward\"].to_numpy()\n",
    "    outcomes[outcomes == 0] = -1\n",
    "    n_trials = choices.size\n",
    "\n",
    "    past_choices = sliding_window_view(choices, npast)[:-1, :]\n",
    "    past_outcomes = sliding_window_view(outcomes, npast)[:-1, :]\n",
    "    actual_choices = choices[npast:]\n",
    "\n",
    "    x = np.hstack(\n",
    "        (\n",
    "            past_choices * past_outcomes,\n",
    "            past_choices,\n",
    "            past_outcomes,\n",
    "        )\n",
    "    )\n",
    "    clf = LogisticRegression(random_state=0).fit(x, actual_choices)\n",
    "\n",
    "    params = np.fliplr(clf.coef_.squeeze().reshape(3, npast))\n",
    "    params_pooled.append(params)\n",
    "\n",
    "    subfig = fig.add_subfigure(fig.gs[i])\n",
    "    subfig.suptitle(f\"{files[i].name[:-4]}, {task_type}\")\n",
    "    sub_axs = subfig.subplots(1, 3, width_ratios=[1, 1, 1], sharey=True, sharex=True)\n",
    "\n",
    "    colors = [\"orange\", \"purple\", \"blue\"]\n",
    "    titles = [\"Reward Seeking\", \"Choice Preservation\", \"Main effect of Outcome\"]\n",
    "    for _, ax in enumerate(sub_axs):\n",
    "\n",
    "        ax.plot(np.arange(1, 11), params[_], \".-\", color=colors[_], zorder=1)\n",
    "        ax.set_title(titles[_])\n",
    "        ax.axhline(0, color=\"gray\", zorder=0, lw=0.8)\n",
    "        ax.set_xticks([1, 5, 10])\n",
    "\n",
    "    if i == 0:\n",
    "        sub_axs[0].set_xlabel(\"Trials in the past\")\n",
    "        sub_axs[0].set_ylabel(\"Influence on current choice\")\n",
    "\n",
    "task_type_bool = np.array(task_type_bool)\n",
    "params_pooled = np.array(params_pooled)\n",
    "mean_struc = params_pooled[task_type_bool < 0.2, :, :].mean(axis=0)\n",
    "mean_unstruc = params_pooled[task_type_bool > 0.2, :, :].mean(axis=0)\n",
    "\n",
    "subfig = fig.add_subfigure(fig.gs[4:, 0:2])\n",
    "subfig.suptitle(f\"Mean across animals by task type\")\n",
    "sub_axs = subfig.subplots(1, 3, width_ratios=[1, 1, 1], sharey=True, sharex=True)\n",
    "\n",
    "# colors = [\"orange\", \"purple\", \"blue\"]\n",
    "colors = [\"#5040BF\", \"#AFBF40\"]\n",
    "\n",
    "\n",
    "titles = [\"Reward Seeking\", \"Choice Preservation\", \"Main effect of Outcome\"]\n",
    "for _, ax in enumerate(sub_axs):\n",
    "\n",
    "    ax.plot(np.arange(1, 11), mean_struc[_], \".-\", color=colors[0], alpha=0.7, zorder=1)\n",
    "    ax.plot(\n",
    "        np.arange(1, 11), mean_unstruc[_], \".-\", color=colors[1], alpha=0.7, zorder=1\n",
    "    )\n",
    "    ax.legend([\"Struc\", \"Unstruc\"])\n",
    "    ax.set_title(titles[_])\n",
    "    ax.axhline(0, color=\"gray\", zorder=0, lw=0.8)\n",
    "    ax.set_xticks([1, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cognitive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))\n",
    "\n",
    "fig = plotting.Fig(6, 3, size=(12, 5), num=1)\n",
    "\n",
    "npast = 10\n",
    "params_pooled = []\n",
    "task_type_bool = []\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    prob_corr = np.abs(\n",
    "        stats.pearsonr(data_df[\"rewprobfull1\"], data_df[\"rewprobfull2\"])[0]\n",
    "    )\n",
    "\n",
    "    task_type = \"unstructured\" if prob_corr < 0.2 else \"structured\"\n",
    "    task_type_bool.append(prob_corr)\n",
    "\n",
    "    choices = data_df[\"port\"].to_numpy()\n",
    "    choices[choices == 2] = -1\n",
    "    outcomes = data_df[\"reward\"].to_numpy()\n",
    "    outcomes[outcomes == 0] = -1\n",
    "    n_trials = choices.size\n",
    "\n",
    "    past_choices = sliding_window_view(choices, npast)[:-1, :]\n",
    "    past_outcomes = sliding_window_view(outcomes, npast)[:-1, :]\n",
    "    actual_choices = choices[npast:]\n",
    "\n",
    "    x = np.hstack(\n",
    "        (\n",
    "            past_choices * past_outcomes,\n",
    "            past_choices,\n",
    "            past_outcomes,\n",
    "        )\n",
    "    )\n",
    "    clf = LogisticRegression(random_state=0).fit(x, actual_choices)\n",
    "\n",
    "    params = np.fliplr(clf.coef_.squeeze().reshape(3, npast))\n",
    "    params_pooled.append(params)\n",
    "\n",
    "    subfig = fig.add_subfigure(fig.gs[i])\n",
    "    subfig.suptitle(f\"{files[i].name[:-4]}, {task_type}\")\n",
    "    sub_axs = subfig.subplots(1, 3, width_ratios=[1, 1, 1], sharey=True, sharex=True)\n",
    "\n",
    "    colors = [\"orange\", \"purple\", \"blue\"]\n",
    "    titles = [\"Reward Seeking\", \"Choice Preservation\", \"Main effect of Outcome\"]\n",
    "    for _, ax in enumerate(sub_axs):\n",
    "\n",
    "        ax.plot(np.arange(1, 11), params[_], \".-\", color=colors[_], zorder=1)\n",
    "        ax.set_title(titles[_])\n",
    "        ax.axhline(0, color=\"gray\", zorder=0, lw=0.8)\n",
    "        ax.set_xticks([1, 5, 10])\n",
    "\n",
    "    if i == 0:\n",
    "        sub_axs[0].set_xlabel(\"Trials in the past\")\n",
    "        sub_axs[0].set_ylabel(\"Influence on current choice\")\n",
    "\n",
    "task_type_bool = np.array(task_type_bool)\n",
    "params_pooled = np.array(params_pooled)\n",
    "mean_struc = params_pooled[task_type_bool < 0.2, :, :].mean(axis=0)\n",
    "mean_unstruc = params_pooled[task_type_bool > 0.2, :, :].mean(axis=0)\n",
    "\n",
    "subfig = fig.add_subfigure(fig.gs[4:, 0:2])\n",
    "subfig.suptitle(f\"Mean across animals by task type\")\n",
    "sub_axs = subfig.subplots(1, 3, width_ratios=[1, 1, 1], sharey=True, sharex=True)\n",
    "\n",
    "colors = [\"orange\", \"purple\", \"blue\"]\n",
    "titles = [\"Reward Seeking\", \"Choice Preservation\", \"Main effect of Outcome\"]\n",
    "for _, ax in enumerate(sub_axs):\n",
    "\n",
    "    ax.plot(np.arange(1, 11), mean_struc[_], \".-\", color=colors[_], zorder=1)\n",
    "    ax.plot(\n",
    "        np.arange(1, 11), mean_unstruc[_], \".-\", color=colors[_], alpha=0.5, zorder=1\n",
    "    )\n",
    "    ax.set_title(titles[_])\n",
    "    ax.axhline(0, color=\"gray\", zorder=0, lw=0.8)\n",
    "    ax.set_xticks([1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Simulated Example Data (Each row: [choice, reward])\n",
    "# data = np.array([[0, 1], [1, 0], [1, 1], [0, 0], [0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "\n",
    "# choices = data[:, 0]  # 0 or 1 (action taken)\n",
    "# rewards = data[:, 1]  # 0 or 1 (reward received)\n",
    "\n",
    "\n",
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))\n",
    "\n",
    "fig = plotting.Fig(6, 3, size=(12, 5), num=1)\n",
    "\n",
    "npast = 10\n",
    "params_pooled = []\n",
    "task_type_bool = []\n",
    "\n",
    "for i, file in enumerate(files[:1]):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    prob_corr = np.abs(\n",
    "        stats.pearsonr(data_df[\"rewprobfull1\"], data_df[\"rewprobfull2\"])[0]\n",
    "    )\n",
    "\n",
    "    task_type = \"unstructured\" if prob_corr < 0.2 else \"structured\"\n",
    "    task_type_bool.append(prob_corr)\n",
    "\n",
    "    choices = data_df[\"port\"].to_numpy().astype(int)\n",
    "    choices[choices == 2] = 0\n",
    "    rewards = data_df[\"reward\"].to_numpy().astype(int)\n",
    "    # rewards[rewards == 0] = -1\n",
    "    n_trials = choices.size\n",
    "\n",
    "    # Q-learning function with given alpha\n",
    "    def compute_q_values(alpha):\n",
    "        Q = np.zeros(2)  # Initialize Q-values for two actions\n",
    "        q_values = []\n",
    "\n",
    "        for choice, reward in zip(choices, rewards):\n",
    "            Q[choice] = Q[choice] + alpha * (reward - Q[choice])\n",
    "            q_values.append(Q.copy())\n",
    "\n",
    "        return np.array(q_values)\n",
    "\n",
    "    # Loss function to optimize alpha (maximize log-likelihood)\n",
    "    def log_likelihood(alpha):\n",
    "        Q_values = compute_q_values(alpha)\n",
    "        X = (Q_values[:, 0] - Q_values[:, 1]).reshape(-1, 1)  # Difference in Q-values\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X, choices)  # Fit logistic regression on choice data\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        probs = model.predict_proba(X)[:, 1]  # Probability of choosing action 1\n",
    "        ll = np.sum(choices * np.log(probs) + (1 - choices) * np.log(1 - probs))\n",
    "        return -ll  # Negative for minimization\n",
    "\n",
    "    # Optimize alpha using a bounded method\n",
    "    result = minimize(log_likelihood, x0=0.5, bounds=[(0, 1)], method=\"L-BFGS-B\")\n",
    "\n",
    "    alpha_estimated = result.x[0]\n",
    "    print(f\"Estimated alpha: {alpha_estimated:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from pybads import BADS\n",
    "\n",
    "basepath = Path(\"D:\\\\Data\")\n",
    "# files = [\"gronckle.csv\", \"grump.csv\"]\n",
    "files = sorted(basepath.glob(\"*.csv\"))\n",
    "\n",
    "# fig = plotting.Fig(6, 3, size=(12, 5), num=1)\n",
    "estimated_params = []\n",
    "task_type = []\n",
    "\n",
    "for i, file in enumerate(files[3:]):\n",
    "    data_df = pd.read_csv(basepath / file)\n",
    "    prob_corr = np.abs(\n",
    "        stats.pearsonr(data_df[\"rewprobfull1\"], data_df[\"rewprobfull2\"])[0]\n",
    "    )\n",
    "\n",
    "    task_type.append(\"unstructured\" if prob_corr < 0.2 else \"structured\")\n",
    "    # task_type_bool.append(prob_corr)\n",
    "\n",
    "    choices = data_df[\"port\"].to_numpy().astype(int)\n",
    "    choices[choices == 2] = 0\n",
    "    rewards = data_df[\"reward\"].to_numpy().astype(int)\n",
    "    session_id = data_df[\"session#\"].to_numpy()\n",
    "    session_starts = np.diff(session_id, prepend=session_id[0])\n",
    "    # rewards[rewards == 0] = -1\n",
    "    n_trials = choices.size\n",
    "\n",
    "    # Q-learning function with different learning rates for left and right\n",
    "    # def compute_q_values(alpha_L, alpha_R):\n",
    "    #     Q = np.zeros(2)  # Q-values: Q[0] for Left, Q[1] for Right\n",
    "    #     q_values = []\n",
    "\n",
    "    #     for choice, reward in zip(choices, rewards):\n",
    "    #         if choice == 0:\n",
    "    #             Q[0] += alpha_L * (reward - Q[0])\n",
    "    #         else:\n",
    "    #             Q[1] += alpha_R * (reward - Q[1])\n",
    "    #         q_values.append(Q.copy())\n",
    "\n",
    "    #     return np.array(q_values)\n",
    "\n",
    "    # def compute_q_values(alpha_c, alpha_u):\n",
    "    #     print(alpha_c, alpha_u)\n",
    "    #     Q = np.zeros(2)  # Q-values: Q[0] for Left, Q[1] for Right\n",
    "    #     q_values = []\n",
    "    #     q_diff = []\n",
    "\n",
    "    #     for choice, reward, start in zip(choices, rewards, session_starts):\n",
    "    #         # If Left (0) is chosen, Right (1) is unchosen, and vice versa\n",
    "    #         unchosen = 1 - choice\n",
    "\n",
    "    #         # Update Q-values for chosen and unchosen arms\n",
    "    #         if start > 0:\n",
    "    #             Q[choice] += 0\n",
    "    #             Q[unchosen] += 0\n",
    "    #         else:\n",
    "    #             # Chosen action update\n",
    "    #             a_ = np.around(alpha_c * (reward - Q[choice]), 4)\n",
    "    #             b_ = np.around(alpha_u * (reward - Q[choice]), 4)\n",
    "\n",
    "    #             # if b_ < -100.0:\n",
    "    #             #     break\n",
    "    #             # print(a_, b_)\n",
    "    #             Q[choice] += a_\n",
    "    #             Q[unchosen] += b_\n",
    "\n",
    "    #         q_values.append(Q.copy())\n",
    "    #         q_diff.append(Q[choice] - Q[unchosen])\n",
    "\n",
    "    #     # print(np.array(q_values).shape)\n",
    "    #     return np.array(q_values), np.array(q_diff)\n",
    "\n",
    "    def compute_q_values(alpha_c, alpha_u):\n",
    "        Q = np.zeros(2)\n",
    "        q_values = []\n",
    "\n",
    "        for choice, reward, start in zip(choices, rewards, session_starts):\n",
    "            if start > 0:\n",
    "                Q[:] = 0.0  # Reset Q-values at session start\n",
    "\n",
    "            unchosen = 1 - choice\n",
    "\n",
    "            # Q-learning update\n",
    "            Q[choice] += alpha_c * (reward - Q[choice])\n",
    "            # Q[unchosen] += alpha_u * ((1 - reward) - Q[unchosen])\n",
    "            Q[unchosen] += alpha_u * (Q[choice] - reward)\n",
    "\n",
    "            q_values.append(Q.copy())\n",
    "\n",
    "        return np.array(q_values)\n",
    "\n",
    "    # Log-likelihood function to optimize alpha_L and alpha_R\n",
    "    def log_likelihood(params):\n",
    "        alpha_c, alpha_u, beta = params\n",
    "        Q_values = compute_q_values(alpha_c, alpha_u)\n",
    "        # Compute softmax probabilities\n",
    "        betaQ = beta * Q_values\n",
    "        betaQ = np.clip(betaQ, -500, 500)  # Prevent overflow\n",
    "        exp_Q = np.exp(betaQ)\n",
    "        probs = exp_Q / np.sum(exp_Q, axis=1, keepdims=True)\n",
    "        print(probs.shape)\n",
    "        # Get the probability of the chosen action\n",
    "        chosen_probs = probs[np.arange(len(choices)), choices]\n",
    "\n",
    "        # Numerical stability\n",
    "        eps = 1e-9\n",
    "        chosen_probs = np.clip(chosen_probs, eps, 1 - eps)\n",
    "\n",
    "        # Log-likelihood\n",
    "        ll = np.sum(np.log(chosen_probs))\n",
    "        return -ll  # For minimization\n",
    "\n",
    "    # Optimize alpha_L and alpha_R using a bounded method\n",
    "    # result = minimize(\n",
    "    #     log_likelihood,\n",
    "    #     x0=[0.63, 0.32, 1.2],\n",
    "    #     bounds=[(0, 1), (-0.3, 1), (1, 10)],\n",
    "    #     method=\"L-BFGS-B\",\n",
    "    #     # method=\"BFGS\",\n",
    "    # )\n",
    "    bads = BADS(\n",
    "        log_likelihood,\n",
    "        x0=np.array([0.3, 0.2, 1.2]),\n",
    "        lower_bounds=np.array([-0.9, -0.9, 1]),\n",
    "        upper_bounds=np.array([0.9, 0.9, 10]),\n",
    "        plausible_lower_bounds=np.array([0, -0.5, 3]),\n",
    "        plausible_upper_bounds=np.array([0.5, 0.1, 5]),\n",
    "    )\n",
    "    result = bads.optimize()\n",
    "\n",
    "    estimated_params.append(result.x)\n",
    "    alpha_L_est, alpha_R_est, beta = result.x\n",
    "    print(\n",
    "        f\"Chosen alpha: {alpha_L_est:.4f}, Unchosen alpha: {alpha_R_est:.4f}, Estimated: beta: {beta}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices.size, session_starts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_starts[session_starts != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3])\n",
    "\n",
    "np.diff(a, prepend=a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "\n",
    "fig = plotting.Fig(1, 2, size=(4, 3), num=1)\n",
    "estimated_params = np.array(estimated_params)\n",
    "ax1 = fig.subplot(fig.gs[0])\n",
    "ax2 = fig.subplot(fig.gs[1])\n",
    "\n",
    "for i in range(estimated_params.shape[0]):\n",
    "    if task_type[i] == \"structured\":\n",
    "        color = \"#5040BF\"\n",
    "    else:\n",
    "        color = \"#AFBF40\"\n",
    "\n",
    "    x1 = np.array([1, 2]) + 0.1 * np.random.randn(2)\n",
    "\n",
    "    ax1.plot(x1, estimated_params[i, :2], \".\", color=color, alpha=0.6)\n",
    "    ax1.set_xlim(0, 3)\n",
    "    ax2.plot(\n",
    "        1 + 0.1 * np.random.randn(1),\n",
    "        estimated_params[i, 2],\n",
    "        \".\",\n",
    "        color=color,\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    ax2.set_xlim(0, 2)\n",
    "\n",
    "# ax1.legend([\"struc\", \"unstruc\"])\n",
    "ax1.set_xticks([1, 2], [\"Alpha_L\", \"Alpha_R\"])\n",
    "ax2.set_xticks([1], [\"Beta\"])\n",
    "ax1.set_ylabel(\"Estimated alpha values\")\n",
    "ax2.set_ylabel(\"Estimated beta values\")\n",
    "fig.fig.suptitle(\"Q-learning in two-armed bandit task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybads import BADS\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def noisy_sphere(x, sigma=1.0):\n",
    "    \"\"\"Simple quadratic function with added noise.\"\"\"\n",
    "    x_2d = np.atleast_2d(x)\n",
    "    f = np.sum(x_2d**2, axis=1)\n",
    "    noise = sigma * np.random.normal(size=x_2d.shape[0])\n",
    "    return f + noise\n",
    "\n",
    "\n",
    "x0 = np.array([-3, -3])\n",
    "# Starting point\n",
    "lower_bounds = np.array([-5, -5])\n",
    "upper_bounds = np.array([5, 5])\n",
    "plausible_lower_bounds = np.array([-2, -2])\n",
    "plausible_upper_bounds = np.array([2, 2])\n",
    "\n",
    "options = {\n",
    "    \"uncertainty_handling\": True,\n",
    "    \"max_fun_evals\": 300,\n",
    "    \"noise_final_samples\": 100,\n",
    "}\n",
    "bads = BADS(\n",
    "    noisy_sphere,\n",
    "    x0,\n",
    "    lower_bounds,\n",
    "    upper_bounds,\n",
    "    plausible_lower_bounds,\n",
    "    plausible_upper_bounds,\n",
    "    options=options,\n",
    ")\n",
    "optimize_result = bads.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 2\n",
    "exec(\"D\" + \"=val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    evaluation_parameters = {\"D\": 2}\n",
    "    for key, val in evaluation_parameters.items():\n",
    "        exec(key + \"=val\")\n",
    "    m = D / 2\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"M\": 3}\n",
    "for k, val in a.items():\n",
    "    print(k, val)\n",
    "    exec(k + \"=val\")\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 2\n",
    "exec(\"D=val\")\n",
    "\n",
    "print(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
